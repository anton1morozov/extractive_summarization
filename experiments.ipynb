{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0d221e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anton/Work/interviews/aspose/repository/extractive_summarization/venv/bin/python\n",
      "/home/anton/Work/interviews/aspose/repository/extractive_summarization/venv/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c44bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (2041.3 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp38-cp38-linux_x86_64.whl (23.2 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in ./venv/lib/python3.8/site-packages (from torchvision==0.10.0+cu111) (8.3.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f69e7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0999f99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/anton/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from fasttext import FastText\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import os\n",
    "\n",
    "from rouge import Rouge\n",
    "\n",
    "# import seaborn as sns\n",
    "from shutil import rmtree\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "nltk.download('all')\n",
    "stopwords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b0393",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3785c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentences(text: str) -> List[str]:\n",
    "    return sent_tokenize(text.replace('\\n', ' ').strip())\n",
    "\n",
    "def sentence_to_words(sentence: str) -> List[str]:\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    return [sentence_to_words(s) for s in text_to_sentences(text)]\n",
    "\n",
    "# def _sentence_to_vec(self, sentence: str) -> np.ndarray:\n",
    "#         vec = np.zeros((self.word2vec.get_dimension(),), dtype=np.float32)\n",
    "#         res = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "#         words = word_tokenize(sentence)\n",
    "#         for word in words:\n",
    "# #             if self.remove_stopwords and word not in stopwords:\n",
    "# #                 vec += self.word2vec.get_word_vector(word)\n",
    "#             vec += self.word2vec.get_word_vector(word)\n",
    "#         return vec / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b530d3",
   "metadata": {},
   "source": [
    "## Summarization metrics\n",
    "BLEU and ROUGE\n",
    "\n",
    "#### BLEU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669a3f50",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Downloading\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "# fasttext.util.download_model('ru', if_exists='ignore')\n",
    "\n",
    "ft_en = fasttext.load_model('cc.en.300.bin')\n",
    "# ft_ru = fasttext.load_model('cc.ru.300.bin')\n",
    "\n",
    "print(ft_en.get_dimension())\n",
    "# print(ft_ru.get_dimension())\n",
    "# ft_en.get_word_vector('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df90e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Одной из областей применения обработки естественного языка является\n",
    "суммаризация текстов, подразумевающая создание краткой версии текста, документа,\n",
    "статьи с помощью машинного обучения. Есть два вида суммаризации: абстрактная или\n",
    "генерирующая, когда на основе существующего текста модель создает новый текст\n",
    "меньшего объема, как правило в исходном тексте представленный лишь частично, и\n",
    "экстрактная или извлекающая, когда модель ранжирует предложения, фразы или\n",
    "абзацы в тексте и отбирает заданное пользователем число наиболее важных\n",
    "элементов, при этом идут они в той же последовательности, что и в оригинальном\n",
    "тексте, из-за чего как правило нарушается связность результата.\n",
    "В качестве тестового задания предлагается реализовать последний подход для\n",
    "суммаризации текстов, как требующий меньше времени и ресурсов.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b298e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = text_to_sentences(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62d5b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = sentence_to_vec(sentence, ft_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c8fef99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array([1, 0]).reshape(1, -1), np.array([0, 1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28d9fb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 0]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58eaef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(*combinations(range(4), 2), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0fead5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news = \"\"\"\n",
    "# Третья волна коронавируса быстрее распространяется из-за новых вариантов COVID-19, сообщил глава Минздрава Михаил Мурашко.\n",
    "# Он назвал эту волну более агрессивной.\n",
    "# «Третья волна, она в силу того, что меняется штамм, более агрессивна и быстрее распространяется среди населения»,— сказал господин Мурашко в ходе рабочей поездки в Астрахань (цитата по ТАСС).\n",
    "# Министр отметил, что дельта-штамм более заразен, при заболевании сокращается инкубационный период и время до развития тяжелых осложнений.\n",
    "# По его словам, часто «уже на пятые сутки формируются грозные тяжелые осложнения».\n",
    "# Михаил Мурашко призвал заболевших обращаться к врачу «фактические в первые сутки», чтобы получить лекарство и начать терапию.\n",
    "# «Тогда исходы позволяют нам держаться обычных стандартных показателей»,— добавил он.\n",
    "# Роспотребнадзор считает, что для борьбы с новыми мутациями нужна ревакцинация раз в полгода.\n",
    "# Ведомство отмечало, что эффект вакцин против дельта-штамма снижается.\n",
    "# Вместе с тем Всемирная организация здравоохранения призывает ввести временный мораторий на ревакцинацию. \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "news = \"\"\"\n",
    "Тегеран не подтверждает информацию о причастности к нападению на танкер-химовоз Mercer Street в Аравийском море.\n",
    "Об этом заявил глава пресс-службы вооруженных сил Ирана Аболфазл Шекарчи.\n",
    "«Если бы нам пришлось противостоять врагам... Мы бы объявили об этом открыто, поэтому недавнее заявление врагов — это психологическая операция»,— сказал господин Шекарчи, комментируя совместное заявление стран G7 о причастности Тегерана к нападению на танкер (цитата по Reuters).\n",
    "Накануне страны G7 выпустили совместное заявление, в котором утверждается, что Иран причастен к нападению 30 июля на танкер Mercer Street в Аравийском море, который следовал под флагом Либерии.\n",
    "Инцидент произошел в 280 км от побережья Омана.\n",
    "В результате погибли два члена экипажа судна — гражданин Румынии и подданный Великобритании.\n",
    "Лондон и Вашингтон заявили, что ведут консультации с союзниками, чтобы дать согласованный ответ на нападение.\n",
    "\"\"\"\n",
    "\n",
    "sentences = text_to_sentences(news)\n",
    "vecs = [sentence_to_vec(s, ft_ru) for s in sentences]\n",
    "matrix = get_similarity_matrix(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d45f2e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa6b9c3c2e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(matrix, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a28c4c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa6b9c0cee0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(matrix / matrix.sum(0)[:, None], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be798fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank(m: np.ndarray, d: float = 0.85, iterations: int = 100, init_value: float = 40) -> np.ndarray:\n",
    "#     assert 0. < init_value <= 1., f\"Initial value must be in interval (0, 1]\"\n",
    "    assert m.shape[0] == m.shape[1], f\"Similarity matrix must be square\"\n",
    "    assert iterations > 0, f\"Iterations count must be \"\n",
    "    ranks = np.full((m.shape[0],), fill_value=init_value)\n",
    "    print(ranks)\n",
    "    \n",
    "#     di = m.sum(0)\n",
    "#     dm = m / di[:, None]\n",
    "#     dm = m / ()\n",
    "#     print(dm)\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        ranks = (1 - d) + d * np.dot(m, ranks)\n",
    "#         new_ranks = ranks.copy()\n",
    "#         for i in range(len(ranks)):\n",
    "# #             new_ranks[i] = ranks[i] * (1 - d) + d * ((ranks * m[i]).sum())\n",
    "#             new_ranks[i] = (1 - d) + d * ((ranks * dm[i]).sum())\n",
    "#         ranks = new_ranks\n",
    "        print(ranks)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eac689a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 40 40 40 40 40 40]\n",
      "[150.4198313  112.87925526 155.17651942 153.03441527 126.43737259\n",
      " 139.78975072 144.3353556 ]\n",
      "[529.54698895 409.32703482 541.0276969  537.27181738 454.18016088\n",
      " 492.86542395 513.8334758 ]\n",
      "[1873.82529014 1443.77821284 1919.01851402 1902.22449702 1603.21422617\n",
      " 1745.36076915 1813.635577  ]\n",
      "[6627.68536448 5108.56802474 6783.8918333  6727.31622838 5672.20169481\n",
      " 6171.7505484  6418.1822918 ]\n",
      "[23441.57197674 18067.48201892 23996.90350631 23794.61648283\n",
      " 20061.3231014  21830.21468672 22698.14398733]\n",
      "[82911.21006533 63903.95126632 84873.18838823 84159.38068392\n",
      " 70955.76657794 77210.9649855  80283.45798644]\n",
      "[293249.7784026  226022.32631772 300190.81912743 297664.87762922\n",
      " 250964.27778882 273089.1967524  283954.45523446]\n",
      "[1037199.60565773  799421.96079785 1061748.18149787 1052815.10109715\n",
      "  887639.32874775  965892.78807596 1004323.64856014]\n",
      "[3668485.77126547 2827486.49794839 3755312.97365624 3723716.71025737\n",
      " 3139503.949962   3416280.05959453 3552205.77305449]\n",
      "[12975118.86173695 10000576.7323378  13282218.45072526 13170465.73386856\n",
      " 11104155.52101316 12083088.62513907 12563846.88005281]\n",
      "[45891879.11026961 35371179.39841164 46978064.5254783  46582804.3648147\n",
      " 39274442.76964825 42736845.10215288 44437245.22923133]\n",
      "[1.62315628e+08 1.25104818e+08 1.66157372e+08 1.64759371e+08\n",
      " 1.38910325e+08 1.51156544e+08 1.57170714e+08]\n",
      "[5.74096412e+08 4.42484979e+08 5.87684330e+08 5.82739721e+08\n",
      " 4.91313868e+08 5.34627692e+08 5.55899291e+08]\n",
      "[2.03052961e+09 1.56503130e+09 2.07858891e+09 2.06110025e+09\n",
      " 1.73773488e+09 1.89093215e+09 1.96616796e+09]\n",
      "[7.18180854e+09 5.53538105e+09 7.35179014e+09 7.28993427e+09\n",
      " 6.14621876e+09 6.68806431e+09 6.95416692e+09]\n",
      "[2.54014389e+10 1.95781665e+10 2.60026492e+10 2.57838703e+10\n",
      " 2.17386469e+10 2.36551080e+10 2.45962901e+10]\n",
      "[8.98427039e+10 6.92462906e+10 9.19691330e+10 9.11953308e+10\n",
      " 7.68877239e+10 8.36660819e+10 8.69949618e+10]\n",
      "[3.17765914e+11 2.44918172e+11 3.25286910e+11 3.22550039e+11\n",
      " 2.71945264e+11 2.95919733e+11 3.07693695e+11]\n",
      "[1.12391070e+12 8.66254502e+11 1.15051181e+12 1.14083174e+12\n",
      " 9.61847001e+11 1.04664264e+12 1.08828613e+12]\n",
      "[3.97517544e+12 3.06386764e+12 4.06926130e+12 4.03502369e+12\n",
      " 3.40197009e+12 3.70188495e+12 3.84917439e+12]\n",
      "[1.40598535e+13 1.08366362e+13 1.43926271e+13 1.42715316e+13\n",
      " 1.20324755e+13 1.30932486e+13 1.36141986e+13]\n",
      "[4.97284921e+13 3.83282500e+13 5.09054838e+13 5.04771795e+13\n",
      " 4.25578306e+13 4.63096937e+13 4.81522493e+13]\n",
      "[1.75885398e+14 1.35563723e+14 1.80048316e+14 1.78533441e+14\n",
      " 1.50523385e+14 1.63793402e+14 1.70310363e+14]\n",
      "[6.22091520e+14 4.79477223e+14 6.36815403e+14 6.31457420e+14\n",
      " 5.32388263e+14 5.79323171e+14 6.02373100e+14]\n",
      "[2.20028418e+15 1.69586968e+15 2.25236129e+15 2.23341056e+15\n",
      " 1.88301148e+15 2.04901621e+15 2.13054183e+15]\n",
      "[7.78221585e+15 5.99814516e+15 7.96640810e+15 7.89938100e+15\n",
      " 6.66004959e+15 7.24719404e+15 7.53554313e+15]\n",
      "[2.75250279e+16 2.12149234e+16 2.81765000e+16 2.79394310e+16\n",
      " 2.35560224e+16 2.56327018e+16 2.66525677e+16]\n",
      "[9.73536554e+16 7.50353587e+16 9.96578563e+16 9.88193634e+16\n",
      " 8.33156244e+16 9.06606608e+16 9.42678388e+16]\n",
      "[3.44331503e+17 2.65393608e+17 3.52481263e+17 3.49515586e+17\n",
      " 2.94680195e+17 3.20658957e+17 3.33417235e+17]\n",
      "[1.21787090e+18 9.38674356e+17 1.24669590e+18 1.23620656e+18\n",
      " 1.04225850e+18 1.13414314e+18 1.17926807e+18]\n",
      "[4.30750459e+18 3.32001044e+18 4.40945614e+18 4.37235623e+18\n",
      " 3.68637863e+18 4.01136671e+18 4.17096972e+18]\n",
      "[1.52352731e+19 1.17425913e+19 1.55958670e+19 1.54646478e+19\n",
      " 1.30384040e+19 1.41878589e+19 1.47523610e+19]\n",
      "[5.38858502e+19 4.15325350e+19 5.51612397e+19 5.46971287e+19\n",
      " 4.61157133e+19 5.01812363e+19 5.21778317e+19]\n",
      "[1.90589616e+20 1.46897003e+20 1.95100559e+20 1.93459038e+20\n",
      " 1.63107310e+20 1.77486715e+20 1.84548501e+20]\n",
      "[6.74099074e+20 5.19562060e+20 6.90053890e+20 6.84247973e+20\n",
      " 5.76896523e+20 6.27755242e+20 6.52732171e+20]\n",
      "[2.38423043e+21 1.83764630e+21 2.44066124e+21 2.42012621e+21\n",
      " 2.04043337e+21 2.22031628e+21 2.30865753e+21]\n",
      "[8.43281788e+21 6.49959687e+21 8.63240881e+21 8.55977818e+21\n",
      " 7.21683726e+21 7.85306765e+21 8.16552304e+21]\n",
      "[2.98261513e+22 2.29885149e+22 3.05320872e+22 3.02751989e+22\n",
      " 2.55253325e+22 2.77756246e+22 2.88807525e+22]\n",
      "[1.05492531e+23 8.13083994e+22 1.07989366e+23 1.07080774e+23\n",
      " 9.02809047e+22 9.82399945e+22 1.02148737e+23]\n",
      "[3.73118006e+23 2.87580813e+23 3.81949095e+23 3.78735484e+23\n",
      " 3.19315792e+23 3.47466408e+23 3.61291293e+23]\n",
      "[1.31968628e+24 1.01714859e+24 1.35092109e+24 1.33955482e+24\n",
      " 1.12939248e+24 1.22895879e+24 1.27785622e+24]\n",
      "[4.66761684e+24 3.59756706e+24 4.77809165e+24 4.73789015e+24\n",
      " 3.99456405e+24 4.34672150e+24 4.51966750e+24]\n",
      "[1.65089592e+25 1.27242852e+25 1.68996991e+25 1.67575098e+25\n",
      " 1.41284293e+25 1.53739800e+25 1.59856751e+25]\n",
      "[5.83907682e+25 4.50047018e+25 5.97727816e+25 5.92698704e+25\n",
      " 4.99710390e+25 5.43764444e+25 5.65399573e+25]\n",
      "[2.06523123e+26 1.59177758e+26 2.11411186e+26 2.09632432e+26\n",
      " 1.76743266e+26 1.92324805e+26 1.99976964e+26]\n",
      "[7.30454518e+26 5.62998035e+26 7.47743175e+26 7.41451876e+26\n",
      " 6.25125723e+26 6.80236289e+26 7.07301318e+26]\n",
      "[2.58355478e+27 1.99127561e+27 2.64470328e+27 2.62245149e+27\n",
      " 2.21101590e+27 2.40593723e+27 2.50166391e+27]\n",
      "[9.13781098e+27 7.04297051e+27 9.35408794e+27 9.27538530e+27\n",
      " 7.82017300e+27 8.50959297e+27 8.84816999e+27]\n",
      "[3.23196512e+28 2.49103807e+28 3.30846042e+28 3.28062398e+28\n",
      " 2.76592791e+28 3.00976982e+28 3.12952160e+28]\n",
      "[1.14311826e+29 8.81058734e+28 1.17017399e+29 1.16032847e+29\n",
      " 9.78284903e+28 1.06452969e+29 1.10688486e+29]\n",
      "[4.04311092e+29 3.11622894e+29 4.13880471e+29 4.10398198e+29\n",
      " 3.46010953e+29 3.76514992e+29 3.91495653e+29]\n",
      "[1.43001355e+30 1.10218336e+30 1.46385962e+30 1.45154312e+30\n",
      " 1.22381097e+30 1.33170113e+30 1.38468644e+30]\n",
      "[5.05783488e+30 3.89832773e+30 5.17754551e+30 5.13398312e+30\n",
      " 4.32851411e+30 4.71011233e+30 4.89751680e+30]\n",
      "[1.78891268e+31 1.37880498e+31 1.83125330e+31 1.81584566e+31\n",
      " 1.53095820e+31 1.66592621e+31 1.73220956e+31]\n",
      "[6.32723023e+31 4.87671457e+31 6.47698537e+31 6.42248985e+31\n",
      " 5.41486743e+31 5.89223765e+31 6.12667616e+31]\n",
      "[2.23788689e+32 1.72485199e+32 2.29085400e+32 2.27157940e+32\n",
      " 1.91519202e+32 2.08403376e+32 2.16695265e+32]\n",
      "[7.91521340e+32 6.10065307e+32 8.10255349e+32 8.03438090e+32\n",
      " 6.77386940e+32 7.37104811e+32 7.66432506e+32]\n",
      "[2.79954288e+33 2.15774850e+33 2.86580346e+33 2.84169140e+33\n",
      " 2.39585933e+33 2.60707630e+33 2.71080583e+33]\n",
      "[9.90174230e+33 7.63177080e+33 1.01361003e+34 1.00508180e+34\n",
      " 8.47394830e+33 9.22100455e+33 9.58788700e+33]\n",
      "[3.50216106e+34 2.69929167e+34 3.58505145e+34 3.55488785e+34\n",
      " 2.99716260e+34 3.26138997e+34 3.39115314e+34]\n",
      "[1.23868423e+35 9.54716239e+34 1.26800185e+35 1.25733325e+35\n",
      " 1.06007063e+35 1.15352557e+35 1.19942169e+35]\n",
      "[4.38111956e+35 3.37674920e+35 4.48481346e+35 4.44707951e+35\n",
      " 3.74937860e+35 4.07992071e+35 4.24225131e+35]\n",
      "[1.54956429e+36 1.19432714e+36 1.58623993e+36 1.57289376e+36\n",
      " 1.32612295e+36 1.44303285e+36 1.50044779e+36]\n",
      "[5.48067559e+36 4.22423233e+36 5.61039416e+36 5.56318990e+36\n",
      " 4.69038278e+36 5.10388304e+36 5.30695474e+36]\n",
      "[1.93846780e+37 1.49407463e+37 1.98434815e+37 1.96765240e+37\n",
      " 1.65894803e+37 1.80519952e+37 1.87702423e+37]\n",
      "[6.85619383e+37 5.28441342e+37 7.01846866e+37 6.95941726e+37\n",
      " 5.86755646e+37 6.38483538e+37 6.63887321e+37]\n",
      "[2.42497677e+38 1.86905156e+38 2.48237198e+38 2.46148601e+38\n",
      " 2.07530424e+38 2.25826134e+38 2.34811233e+38]\n",
      "[8.57693418e+38 6.61067455e+38 8.77993611e+38 8.70606422e+38\n",
      " 7.34017253e+38 7.98727606e+38 8.30507130e+38]\n",
      "[3.03358783e+39 2.33813871e+39 3.10538786e+39 3.07926001e+39\n",
      " 2.59615587e+39 2.82503082e+39 2.93743226e+39]\n",
      "[1.07295391e+40 8.26979546e+39 1.09834897e+40 1.08910777e+40\n",
      " 9.18237994e+39 9.99189095e+39 1.03894452e+40]\n",
      "[3.79494568e+40 2.92495550e+40 3.88476580e+40 3.85208048e+40\n",
      " 3.24772878e+40 3.53404586e+40 3.67465737e+40]\n",
      "[1.34223963e+41 1.03453159e+41 1.37400824e+41 1.36244772e+41\n",
      " 1.14869373e+41 1.24996161e+41 1.29969470e+41]\n",
      "[4.74738610e+41 3.65904924e+41 4.85974893e+41 4.81886038e+41\n",
      " 4.06283088e+41 4.42100668e+41 4.59690831e+41]\n",
      "[1.67910962e+42 1.29417423e+42 1.71885138e+42 1.70438946e+42\n",
      " 1.43698833e+42 1.56367203e+42 1.62588692e+42]\n",
      "[5.93886625e+42 4.57738292e+42 6.07942945e+42 6.02827886e+42\n",
      " 5.08250408e+42 5.53057342e+42 5.75062215e+42]\n",
      "[2.10052590e+43 1.61898096e+43 2.15024189e+43 2.13215037e+43\n",
      " 1.79763796e+43 1.95611624e+43 2.03394558e+43]\n",
      "[7.42937937e+43 5.72619635e+43 7.60522056e+43 7.54123240e+43\n",
      " 6.35809081e+43 6.91861482e+43 7.19389050e+43]\n",
      "[2.62770756e+44 2.02530638e+44 2.68990108e+44 2.66726902e+44\n",
      " 2.24880201e+44 2.44705454e+44 2.54441718e+44]\n",
      "[9.29397557e+44 7.16333441e+44 9.51394868e+44 9.43390102e+44\n",
      " 7.95381924e+44 8.65502135e+44 8.99938464e+44]\n",
      "[3.28719919e+45 2.53360975e+45 3.36500179e+45 3.33668962e+45\n",
      " 2.81319743e+45 3.06120659e+45 3.18300492e+45]\n",
      "[1.16265407e+46 8.96115970e+45 1.19017218e+46 1.18015841e+46\n",
      " 9.95003728e+45 1.08272243e+46 1.12580145e+46]\n",
      "[4.11220742e+46 3.16948508e+46 4.20953661e+46 4.17411876e+46\n",
      " 3.51924258e+46 3.82949608e+46 3.98186288e+46]\n",
      "[1.45445238e+47 1.12101960e+47 1.48887688e+47 1.47634989e+47\n",
      " 1.24472582e+47 1.35445982e+47 1.40835064e+47]\n",
      "[5.14427294e+47 3.96494989e+47 5.26602942e+47 5.22172255e+47\n",
      " 4.40248813e+47 4.79060784e+47 4.98121504e+47]\n",
      "[1.81948508e+48 1.40236866e+48 1.86254930e+48 1.84687834e+48\n",
      " 1.55712217e+48 1.69439677e+48 1.76181290e+48]\n",
      "[6.43536218e+48 4.96005730e+48 6.58767662e+48 6.53224978e+48\n",
      " 5.50740716e+48 5.99293561e+48 6.23138065e+48]\n",
      "[2.27613223e+49 1.75432959e+49 2.33000454e+49 2.31040055e+49\n",
      " 1.94792253e+49 2.11964976e+49 2.20398572e+49]\n",
      "[8.05048388e+49 6.20491283e+49 8.24102559e+49 8.17168794e+49\n",
      " 6.88963438e+49 7.49701884e+49 7.79530787e+49]\n",
      "[2.84738688e+50 2.19462428e+50 2.91477985e+50 2.89025572e+50\n",
      " 2.43680440e+50 2.65163106e+50 2.75713333e+50]\n",
      "[1.00709624e+51 7.76219726e+50 1.03093255e+51 1.02225858e+51\n",
      " 8.61876751e+50 9.37859091e+50 9.75174335e+50]\n",
      "[3.56201276e+51 2.74542239e+51 3.64631974e+51 3.61564064e+51\n",
      " 3.04838392e+51 3.31712691e+51 3.44910772e+51]\n",
      "[1.25985327e+52 9.71032277e+51 1.28967192e+52 1.27882099e+52\n",
      " 1.07818716e+52 1.17323925e+52 1.21991973e+52]\n",
      "[4.45599261e+52 3.43445762e+52 4.56145862e+52 4.52307981e+52\n",
      " 3.81345523e+52 4.14964628e+52 4.31475111e+52]\n",
      "[1.57604625e+53 1.21473811e+53 1.61334867e+53 1.59977441e+53\n",
      " 1.34878630e+53 1.46769419e+53 1.52609034e+53]\n",
      "[5.57433997e+53 4.29642418e+53 5.70627543e+53 5.65826445e+53\n",
      " 4.77054111e+53 5.19110806e+53 5.39765024e+53]\n",
      "[1.97159609e+54 1.51960827e+54 2.01826052e+54 2.00127945e+54\n",
      " 1.68729935e+54 1.83605026e+54 1.90910245e+54]\n",
      "[6.97336573e+54 5.37472369e+54 7.13841383e+54 7.07835324e+54\n",
      " 5.96783262e+54 6.49395179e+54 6.75233111e+54]\n",
      "[2.46641946e+55 1.90099353e+55 2.52479555e+55 2.50355264e+55\n",
      " 2.11077105e+55 2.29685488e+55 2.38824142e+55]\n",
      "[8.72351342e+55 6.72365055e+55 8.92998464e+55 8.85485029e+55\n",
      " 7.46561560e+55 8.12377808e+55 8.44700442e+55]\n",
      "[3.08543164e+56 2.37809735e+56 3.15845873e+56 3.13188436e+56\n",
      " 2.64052400e+56 2.87331041e+56 2.98763279e+56]\n",
      "[3.08543164e+56 2.37809735e+56 3.15845873e+56 3.13188436e+56\n",
      " 2.64052400e+56 2.87331041e+56 2.98763279e+56]\n"
     ]
    }
   ],
   "source": [
    "ranks = textrank(matrix)\n",
    "print(ranks)\n",
    "# nx_graph = nx.from_numpy_array(matrix)\n",
    "# scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6ae0384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 0.1517488912087936), (1, 0.11871791422061005), (2, 0.15602764876042094), (3, 0.1540501923781136), (4, 0.1306368876737971), (5, 0.1425194999362859), (6, 0.14629896582197882)])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11140b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(25).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8f6e1cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.15602764876042094),\n",
       " (3, 0.1540501923781136),\n",
       " (0, 0.1517488912087936),\n",
       " (6, 0.14629896582197882),\n",
       " (5, 0.1425194999362859),\n",
       " (4, 0.1306368876737971),\n",
       " (1, 0.11871791422061005)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(scores.items()), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ac18543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9, 14, 19, 24])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([4, 9, 14, 19, 24])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a44551d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.25      , 0.5       , 0.75      , 1.        ],\n",
       "       [0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ],\n",
       "       [0.71428571, 0.78571429, 0.85714286, 0.92857143, 1.        ],\n",
       "       [0.78947368, 0.84210526, 0.89473684, 0.94736842, 1.        ],\n",
       "       [0.83333333, 0.875     , 0.91666667, 0.95833333, 1.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / b[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26d9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLangSummarizer:\n",
    "    \n",
    "    def __init__(self, word2vec, remove_stopwords=False, lemmatize=False):\n",
    "        self.word2vec = word2vec\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.lemmatize = lemmatize\n",
    "        \n",
    "    def _text_to_sentences(self, text: str) -> List[str]:\n",
    "        return sent_tokenize(text.replace('\\n', ' ').strip())\n",
    "    \n",
    "    def _sentence_to_vec(self, sentence: str) -> np.ndarray:\n",
    "        vec = np.zeros((self.word2vec.get_dimension(),), dtype=np.float32)\n",
    "        res = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "#             if self.remove_stopwords and word not in stopwords:\n",
    "#                 vec += self.word2vec.get_word_vector(word)\n",
    "            vec += self.word2vec.get_word_vector(word)\n",
    "        return vec / len(words)\n",
    "    \n",
    "    def _get_similarity_matrix(self, sentences) -> np.ndarray:\n",
    "        matrix = np.zeros((len(sentences), len(sentences)), dtype=np.float32)\n",
    "        for i, j in combinations(range(len(sentences)), 2):\n",
    "            similarity = cosine_similarity(sentences[i].reshape(1, -1), sentences[j].reshape(1, -1))\n",
    "            matrix[i][j] = matrix[j][i] = similarity  \n",
    "        return matrix\n",
    "        \n",
    "    def summarize(self, text: str, k: int) -> str:\n",
    "        sentences = self._text_to_sentences(text)\n",
    "#         print('debug: sentences:')\n",
    "#         print(*sentences, sep='\\n')\n",
    "        vecs = [self._sentence_to_vec(s) for s in sentences]\n",
    "        matrix = self._get_similarity_matrix(vecs)\n",
    "        nx_graph = nx.from_numpy_array(matrix)\n",
    "        scores = nx.pagerank(nx_graph)\n",
    "        sorted_scores = sorted(list(scores.items()), key=lambda x: x[1], reverse=True)[:k]\n",
    "        result_idxs = [e[0] for e in sorted(sorted_scores, key=lambda x: x[0])]\n",
    "        result = ' '.join(sentences[i] for i in result_idxs)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3cbba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тегеран не подтверждает информацию о причастности к нападению на танкер-химовоз Mercer Street в Аравийском море. «Если бы нам пришлось противостоять врагам... Мы бы объявили об этом открыто, поэтому недавнее заявление врагов — это психологическая операция»,— сказал господин Шекарчи, комментируя совместное заявление стран G7 о причастности Тегерана к нападению на танкер (цитата по Reuters). Накануне страны G7 выпустили совместное заявление, в котором утверждается, что Иран причастен к нападению 30 июля на танкер Mercer Street в Аравийском море, который следовал под флагом Либерии.\n"
     ]
    }
   ],
   "source": [
    "summarizer = SingleLangSummarizer(ft_ru)\n",
    "print(summarizer.summarize(news, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scitldr_testset = '/home/anton/Work/interviews/aspose/datasets/scitldr-master/SciTLDR-Data/SciTLDR-FullText/test.jsonl'\n",
    "with open(scitldr_testset, 'r') as fp:\n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8d351a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source\": [\"Incremental class learning involves sequentially learning classes in bursts of examples from the same class.\", \"This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.\", \"Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale.\", \"Here, we propose FearNet for incremental class learning.\", \"FearNet is a generative model that does not store previous examples, making it memory efficient.\", \"FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex.\", \"Memory consolidation is inspired by mechanisms that occur during sleep.\", \"FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  \", \"FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\\\\n\", \"In incremental classification, an agent must sequentially learn to classify training examples, without necessarily having the ability to re-study previously seen examples.\", \"While deep neural networks (DNNs) have revolutionized machine perception BID26 , off-the-shelf DNNs cannot incrementally learn classes due to catastrophic forgetting.\", \"Catastrophic forgetting is a phenomenon in which a DNN completely fails to learn new data without forgetting much of its previously learned knowledge BID29 .\", \"While methods have been developed to try and mitigate catastrophic forgetting, as shown in BID23 , these methods are not sufficient and perform poorly on larger datasets.\", \"In this paper, we propose FearNet, a brain-inspired system for incrementally learning categories that significantly outperforms previous methods.\", \"The standard way for dealing with catastrophic forgetting in DNNs is to avoid it altogether by mixing new training examples with old ones and completely re-training the model offline.\", \"For large datasets, this may require weeks of time, and it is not a scalable solution.\", \"An ideal incremental learning system would be able to assimilate new information without the need to store the entire training dataset.\", \"A major application for incremental learning includes real-time operation on-board embedded platforms that have limited computing power, storage, and memory, e.g., smart toys, smartphone applications, and robots.\", \"For example, a toy robot may need to learn to recognize objects within its local environment and of interest to its owner.\", \"Using cloud computing to overcome these resource limitations may pose privacy risks and may not be scalable to a large number of embedded devices.\", \"A better solution is on-device incremental learning, which requires the model to use less storage and computational power.\", \"In this paper, we propose an incremental learning framework called FearNet (see Fig. 1 ).\", \"FearNet has three brain-inspired sub-systems: 1) a recent memory system for quick recall, 2) a memory system for long-term storage, and 3) a sub-system that determines which memory system to use for a particular example.\", \"FearNet mitigates catastrophic forgetting by consolidating recent memories into long-term storage using pseudorehearsal BID34 .\", \"Pseudorehearsal allows the network to revisit previous memories during incremental training without the need to store previous training examples, which is more memory efficient.\", \"Figure 1: FearNet consists of three braininspired modules based on 1) mPFC (longterm storage), 2) HC (recent storage), and 3) BLA for determining whether to use mPFC or HC for recall.\", \"Problem Formulation:\", \"Here, incremental class learning consists of T study-sessions.\", \"At time t, the learner receives a batch of data B t , which contains N t labeled training samples, i.e., B t = {(x j , y j )} Nt j=1 , where x j \\\\u2208 R d is the input feature vector to be classified and y j is its corresponding label.\", \"The number of training samples N t may vary between sessions, and the data inside a study-session is not assumed to be independent and identically distributed (iid).\", \"During a study session, the learner only has access to its current batch, but it may use its own memory to store information from prior study sessions.\", \"We refer to the first session as the model\\'s \\\\\"base-knowledge,\\\\\" which contains exemplars from M \\\\u2265 1 classes.\", \"The batches learned in all subsequent sessions contain only one class, i.e., all y j will be identical within those sessions.\", \"Novel Contributions: Our contributions include:1.\", \"FearNet\\'s architecture includes three neural networks: one inspired by the hippocampal complex (HC) for recent memories, one inspired by the medial prefrontal cortex (mPFC) for long-term storage, and one inspired by the basolateral amygdala (BLA) that determines whether to use HC or mPFC for recall.2.\", \"Motivated by memory replay during sleep, FearNet employs a generative autoencoder for pseudorehearsal, which mitigates catastrophic forgetting by generating previously learned examples that are replayed alongside novel information during consolidation.\", \"This process does not involve storing previous training data.3.\", \"FearNet achieves state-of-the-art results on large image and audio datasets with a relatively small memory footprint, demonstrating how dual-memory models can be scaled.\", \"Catastrophic forgetting in DNNs occurs due to the plasticity-stability dilemma BID0 .\", \"If the network is too plastic, older memories will quickly be overwritten; however, if the network is too stable, it is unable to learn new data.\", \"This problem was recognized almost 30 years ago BID29 BID14 , methods developed in the 1980s and 1990s are extensively discussed, and French argued that mitigating catastrophic forgetting would require having two separate memory centers: one for the long-term storage of older memories and another to quickly process new information as it comes in.\", \"He also theorized that this type of dual-memory system would be capable of consolidating memories from the fast learning memory center to longterm storage.\", \"Catastrophic forgetting often occurs when a system is trained on non-iid data.\", \"One strategy for reducing this phenomenon is to mix old examples with new examples, which simulates iid conditions.\", \"For example, if the system learns ten classes in a study session and then needs to learn 10 new classes in a later study session, one solution could be to mix examples from the first study session into the later study session.\", \"This method is known as rehearsal, and it is one of the earliest methods for reducing catastrophic forgetting BID22 .\", \"Rehearsal essentially uses an external memory to strengthen the model\\'s representations for examples learned previously, so that they are not overwritten when learning data from new classes.\", \"Rehearsal reduces forgetting, but performance is still worse than offline models.\", \"Moreover, rehearsal requires storing all of the training data.\", \"BID34 argued that storing of training examples was inefficient and of \\\\\"little interest,\\\\\" so he introduced pseudorehearsal.\", \"Rather than replaying past training data, in pseudorehearsal, the algorithm generates new examples for a given class.\", \"In BID34 , this was done by creating random input vectors, having the network assign them a label, and then mixing them into the new training data.\", \"This idea was revived in BID8 , where a generative autoencoder was used to create pseudo-examples for unsupervised incremental learning.\", \"This method inspired FearNet\\'s approach to memory consolidation.\", \"Pseudorehearsal is related to memory replay that occurs in mammalian brains, which involves reactivation of recently encoded memories in HC so that they can be integrated into long-term storage in mPFC BID31 .Recently there has been renewed interest in solving catastrophic forgetting in supervised learning.\", \"Many new methods are designed to mitigate catastrophic forgetting when each study session contains a permuted version of the entire training dataset (see BID20 ).\", \"Unlike incremental class learning, all labels are contained in each study session.\", \"PathNet uses an evolutionary algorithm to find the optimal path through a large DNN, and then freezes the weights along that path BID11 .\", \"It assumes all classes are seen in each study session, and it is not capable of incremental class learning.\", \"Elastic Weight Consolidation (EWC) employs a regularization scheme that redirects plasticity to the weights that are least important to previously learned study sessions BID24 .\", \"After EWC learns a study session, it uses the training data to build a Fisher matrix that determines the importance of each feature to the classification task it just learned.\", \"EWC was shown to work poorly at incremental class learning in BID23 .The Fixed Expansion Layer (FEL) model mitigates catastrophic forgetting by using sparse updates BID6 .\", \"FEL uses two hidden layers, where the second hidden layer (i.e., the FEL layer) has connectivity constraints.\", \"The FEL layer is much larger than the first hidden layer, is sparsely populated with excitatory and inhibitory weights, and is not updated during training.\", \"This limits learning of dense shared representations, which reduces the risk of learning interfering with old memories.\", \"FEL requires a large number of units to work well BID23 .\", \"Figure 2: iCaRL\\'s performance depends heavily on the number of exemplars per class (EPC) that it stores.\", \"Reducing EPC from 20 (blue) to 1 (red) severely impairs its ability to recall older information.\", \"Gepperth & Karaoguz (2016) introduced a new approach for incremental learning, which we call GeppNet.\", \"GeppNet uses a self-organizing map (SOM) to reorganize the input onto a two-dimensional lattice.\", \"This serves as a long-term memory, which is fed into a simple linear layer for classification.\", \"After the SOM is initialized, it can only be updated if the input is sufficiently novel.\", \"This prevents the model from forgetting older data too quickly.\", \"GeppNet also uses rehearsal using all previous training data.\", \"A variant of GeppNet, GeppNet+STM, uses a fixed-size memory buffer to store novel examples.\", \"When this buffer is full, it replaces the oldest example.\", \"During pre-defined intervals, the buffer is used to train the model.\", \"GeppNet+STM is better at retaining base-knowledge since it only trains during its consolidation phase, but the STM-free version learns new data better because it updates the model on every novel labeled input.iCaRL BID33 is an incremental class learning framework.\", \"Rather than directly using a DNN for classification, iCaRL uses it for supervised representation learning.\", \"During a study session, iCaRL updates a DNN using the study session\\'s data and a set of J stored examples from earlier sessions (J = 2, 000 for CIFAR-100 in their paper), which is a kind of rehearsal.\", \"After a study session, the J examples retained are carefully chosen using herding.\", \"After learning the entire dataset, iCaRL has retained J/T exemplars per class (e.g., J/T = 20 for CIFAR-100).\", \"The DNN in iCaRL is then used to compute an embedding for each stored example, and then the mean embedding for each class seen is computed.\", \"To classify a new instance, the DNN is used to compute an embedding for it, and then the class with the nearest mean embedding is assigned.\", \"iCaRL\\'s performance is heavily influenced by the number of examples it stores, as shown in Fig. 2 .\", \"FearNet is heavily inspired by the dual-memory model of mammalian memory BID28 , which has considerable experimental support from neuroscience BID12 BID38 BID25 BID4 BID39 BID15 .\", \"This theory proposes that HC and mPFC operate as complementary memory systems, where HC is responsible for recalling recent memories and mPFC is responsible for recalling remote (mature) memories.\", \"GeppNet is the most recent DNN to be based on this theory, but it was also independently explored in the 1990s in French (1997) and BID3 .\", \"In this section, we review some of the evidence for the dual-memory model.\", \"One of the major reasons why HC is thought to be responsible for recent memories is that if HC is bilaterally destroyed, then anterograde amnesia occurs with old memories for semantic information preserved.\", \"One mechanism HC may use to facilitate creating new memories is adult neurogenesis.\", \"This occurs in HC\\'s dentate gyrus BID2 BID9 .\", \"The new neurons have higher initial plasticity, but it reduces as time progresses BID7 .In contrast, mPFC is responsible for the recall of remote (long-term) memories BID4 .\", \"BID39 and BID15 showed that mPFC plays a strong role in memory consolidation during REM sleep.\", \"BID28 and BID10 theorized that, during sleep, HC reactivates recent memories to prevent forgetting which causes these recent memories to replay in mPFC as well, with dreams possibly being caused by this process.\", \"After memories are transferred from HC to mPFC, evidence suggests that corresponding memory in HC is erased (Poe, 2017).Recently, BID25 performed contextual fear conditioning (CFC) experiments in mice to trace the formation and consolidation of recent memories to long-term storage.\", \"CFC experiments involve shocking mice while subjecting them to various visual stimuli (i.e., colored lights).\", \"They found that BLA, which is responsible for regulating the brain\\'s fear response, would shift where it retrieved the corresponding memory from (HC or mPFC) as that memory was consolidated over time.\", \"FearNet follows the memory consolidation theory proposed by BID25 .\", \"FearNet has two complementary memory centers, 1) a short-term memory system that immediately learns new information for recent recall (HC) and 2) a DNN for the storage of remote memories (mPFC).\", \"FearNet also has a separate BLA network that determines which memory center contains the associated memory required for prediction.\", \"During sleep phases, FearNet uses a generative model to consolidate data from HC to mPFC through pseudorehearsal.\", \"Pseudocode for FearNet is provided in the supplemental material.\", \"Because the focus of our work is not representation learning, we use pre-trained ResNet embeddings to obtain features that are fed to FearNet.\", \"FearNet\\'s HC model is a variant of a probabilistic neural network BID37 .\", \"HC computes class conditional probabilities using stored training examples.\", \"Formally, HC estimates the probability that an input feature vector x belongs to class k as DISPLAYFORM0 (1) DISPLAYFORM1 where > 0 is a regularization parameter and u k,j is the j\\'th stored exemplar in HC for class k. All exemplars are removed from HC after they are consolidated into mPFC.FearNet\\'s mPFC is implemented using a DNN trained both to reconstruct its input using a symmetric encoder-decoder (autoencoder) and to compute P mP F C (C = k|x).\", \"The autoencoder enables us to The mPFC and BLA sub-systems in FearNet.\", \"mPFC is responsible for the long-term storage of remote memories.\", \"BLA is used during prediction time to determine if the memory should be recalled from short-or long-term memory.use pseudorehearsal, which is described in more detail in Sec. 4.2.\", \"The loss function for mPFC is DISPLAYFORM2 where L class is the supervised classification loss and L recon is the unsupervised reconstruction loss, as illustrated in FIG1 .\", \"For L class , we use standard softmax loss.\", \"L recon is the weighted sum of mean squared error (MSE) reconstruction losses from each layer, which is given by DISPLAYFORM3 where M is the number of mPFC layers, H j is the number of hidden units in layer j, h encoder,(i,j) and h decoder, (i,j) are the outputs of the encoder/decoder at layer j respectively, and \\\\u03bb j is the reconstruction weight for that layer.\", \"mPFC is similar to a Ladder Network BID32 , which combines classification and reconstruction to improve regularization, especially during lowshot learning.\", \"The \\\\u03bb j hyperparameters were found empirically, with \\\\u03bb 0 being largest and decreasing for deeper layers (see supplementary material).\", \"This prioritizes the reconstruction task, which makes the generated pseudo-examples more realistic.\", \"When training is completed during a study session, all of the data in HC is pushed through the encoder to extract a dense feature representation of the original data, and then we compute a mean feature vector \\\\u00b5 c and covariance matrix \\\\u03a3 c for each class c. These are stored and used to generate pseudo-examples during consolidation (see Sec. 4.2).\", \"We study FearNet\\'s performance as a function of how much data is stored in HC in Sec. 6.2.\", \"During FearNet\\'s sleep phase, the original inputs stored in HC are transferred to mPFC using pseudo-examples created by an autoencoder.\", \"This process is known as intrinsic replay, and it was used by Draelos et al. FORMULA1 for unsupervised learning.\", \"Using the class statistics from the encoder, pseudo-examples for class c are generated by sampling a Gaussian with mean \\\\u00b5 c and covariance matrix \\\\u03a3 c to obtainx rand .\", \"Then,x rand is passed through the decoder to generate a pseudo-example.\", \"To create a balanced training set, for each class that mPFC has learned, we generate m pseudo-examples, where m is the average number of examples per class stored in HC.\", \"The pseudo-examples are mixed with the data in HC, and the mixture is used to fine-tune mPFC using backpropagation.\", \"After consolidation, all units in HC are deleted.\", \"During prediction, FearNet uses the BLA network ( FIG1 ) to determine whether to classify an input x using HC or mPFC.\", \"This can be challenging because if HC has only been trained on one class, it will put all of its probability mass on that class, whereas mPFC will likely be less confident.\", \"The output of BLA is given by A (x) and will be a value between 0 and 1, with a 1 indicating mPFC should be used.\", \"BLA is trained after each study session using only the data in HC and with pseudoexamples generated with mPFC, using the same procedure described in Sec. 4.2.\", \"Instead of using solely BLA to determine which network to use, we found that combining its output with those of mPFC and HC improved results.\", \"The predicted class\\\\u0177 is computed a\\\\u015d DISPLAYFORM0 where DISPLAYFORM1 \\\\u03c8 is the probability of the class according to HC weighted by the confidence that the associated memory is actually stored in HC.\", \"BLA has the same number of layers/units as the mPFC encoder, and uses a logistic output unit.\", \"We discuss alternative BLA models in supplemental material.\", \"Evaluating Incremental Learning Performance.\", \"To evaluate how well the incrementally trained models perform compared to an offline model, we use the three metrics proposed in BID23 .\", \"After each study session t in which a model learned a new class k, we compute the model\\'s test accuracy on the new class (\\\\u03b1 new,t ), the accuracy on the base-knowledge (\\\\u03b1 base,t ), and the accuracy of all of the test data seen to this point (\\\\u03b1 all,t ).\", \"After all T study sessions are complete, a model\\'s ability to retain the base-knowledge is given by DISPLAYFORM0 , where \\\\u03b1 of f line is the accuracy of a multi-layer perceptron (MLP) trained offline (i.e., it is given all of the training data at once).\", \"The model\\'s ability to immediately recall new information is measured by and \\\\u2126 all are relative to an offline MLP model, so a value of 1 indicates that a model has similar performance to the offline baseline.\", \"This allows results across datasets to be better compared.\", \"Note that \\\\u2126 base > 1 and \\\\u2126 all > 1 only if the incremental learning algorithm is more accurate than the offline model, which can occur due to better regularization strategies employed by different models.\", \"Datasets.\", \"We evaluate all of the models on three benchmark datasets TAB1 : CIFAR-100, CUB-200, and AudioSet.\", \"CIFAR-100 is a popular image classification dataset containing 100 mutually-exclusive object categories, and it was used in BID33 to evaluate iCaRL.\", \"All images are 32 \\\\u00d7 32 pixels.\", \"CUB-200 is a fine-grained image classification dataset containing high resolution images of 200 different bird species BID40 .\", \"We use the 2011 version of the dataset.\", \"AudioSet is an audio classification dataset BID16 .\", \"We use the variant of AudioSet used by BID23 , which contains a 100 class subset such that none of the classes were super-or sub-classes of one another.\", \"Also, since the AudioSet data samples can have more than one class, the chosen samples had only one of the 100 classes chosen in this subset.\", \"DISPLAYFORM1 For CIFAR-100 and CUB-200, we extract ResNet-50 image embeddings as the input to each of the models, where ResNet-50 was pre-trained on ImageNet BID21 .\", \"We use the output after the mean pooling layer and normalize the features to unit length.\", \"For AudioSet, we use the audio CNN embeddings produced by pre-training the model on the YouTube-8M dataset BID1 .\", \"We use the pre-extracted AudioSet feature embeddings, which represent ten second sound clips (i.e., ten 128-dimensional vectors concatenated in order).Comparison Models.\", \"We compare FearNet to FEL, GeppNet, GeppNet+STM, iCaRL, and an onenearest neighbor (1-NN).\", \"FEL, GeppNet, and GeppNet+STM were chosen due to their previously reported efficacy at incremental class learning in BID23 .\", \"iCARL is explicitly designed for incremental class learning, and represents the state-of-the-art on this problem.\", \"We compare against 1-NN due to its similarity to our HC model.\", \"1-NN does not forget any previously observed examples, but it tends to have worse generalization error than parametric methods and requires storing all of the training data.\", \"In each of our experiments, all models take the same feature embedding as input for a given dataset.\", \"This required modifying iCaRL by turning its CNN into a fully connected network.\", \"We performed a hyperparameter search for each model/dataset combination to tune the number of units and layers (see Supplemental Materials).Training Parameters.\", \"FearNet was implemented in Tensorflow.\", \"For mPFC and BLA, each fully connected layer uses an exponential linear unit activation function BID5 .\", \"The output of the encoder also connects to a softmax output layer.\", \"Xavier initialization is used to initialize all weight layers BID19 , and all of the biases are initialized to one.\", \"BLA\\'s architecture is identical to mPFC\\'s encoder, except it has a logistic output unit, instead of a softmax layer.mPFC and BLA were trained using NAdam.\", \"We train mPFC on the base-knowledge set for 1,000 epochs, consolidate HC over to mPFC for 60 epochs, and train BLA for 20 epochs.\", \"Because mPFC\\'s decoder is vital to preserving memories, its learning rate is 1/100 times lower than the encoder.\", \"We performed a hyperparameter search for each dataset and model, varying the model shape (64-1,024 units), depth (2-4 layers), and how often to sleep (see Sec. 6.2).\", \"Across datasets, mPFC and BLA performed best with two hidden layers, but the number of units per layer varied across datasets.\", \"The specific values used for each dataset are given in supplemental material.\", \"In preliminary experiments, we found no benefit to adding weight decay to mPFC, likely because the reconstruction task helps regularize the model.\", \"Unless otherwise noted, each class is only seen in one unique study-session and the first baseknowledge study session contains half the classes in the dataset.\", \"We perform additional experiments to study how changing the number of base-knowledge classes affects performance in Sec. 6.2.\", \"Unless otherwise noted, FearNet sleeps every 10 study sessions across datasets.\", \"TAB2 shows incremental class learning summary results for all six methods.\", \"FearNet achieves the best \\\\u2126 base and \\\\u2126 all on all three datasets.\", \"FIG3 shows that FearNet more closely resembles the offline MLP baseline than other methods.\", \"\\\\u2126 new measures test accuracy on the most recently trained class.\", \"1 For FearNet, this measures the performance of HC and BLA.\", \"\\\\u2126 new does not account for how well the class was consolidated into mPFC which happens later during a sleep phase; however, \\\\u2126 all does account for this.\", \"FEL achieves a high \\\\u2126 new score because it is able to achieve nearly perfect test accuracy on every new class it learns, but this results in forgetting more quickly than FearNet.\", \"1-NN is similar to our HC model; but on its own, it fails to generalize as well as FearNet, is memory inefficient, and is slow to make predictions.\", \"The final mean-class test accuracy for the offline MLP used to normalize the metrics is 69.9% for CIFAR-100, 59.8% for CUB-200, and 45.8% for AudioSet.\", \"Table 3 : FearNet performance when the location of the associated memory is known using an oracle versus using BLA.\", \"Novelty Detection with BLA.\", \"We evaluated the performance of BLA by comparing it to an oracle version of FearNet, i.e., a version that knew if the relevant memory was stored in either mPFC or HC.\", \"Table 3 shows that FearNet\\'s BLA does a good job at predicting which network to use; however, the decrease in \\\\u2126 new suggests BLA is sometimes using mPFC when it should be using HC.\", \"FIG5 , it is better able to retain its base-knowledge, but this reduces its ability to recall new information.\", \"In humans, sleep deprivation is known to impair new learning BID41 , and that forgetting occurs during sleep BID30 .\", \"Each time FearNet sleeps, the mPFC weights are perturbed which can cause it to gradually forget older memories.\", \"Sleeping less causes HC\\'s recall performance to deteriorate.\", \"Table 4 : Multi-modal incremental learning experiment.\", \"FearNet was trained with various base-knowledge sets (column-header) and then incrementally trained on all remaining data.\", \"Multi-Modal Incremental Learning.\", \"As shown in Sec. 6.1, FearNet can incrementally learn and retain information from a single dataset, but how does it perform if new inputs differ greatly from previously learned ones?\", \"This scenario is one of the first shown to cause catastrophic forgetting in MLPs.\", \"To study this, we trained FearNet to incrementally learn CIFAR-100 and AudioSet, which after training is a 200-way classification problem.\", \"To do this, AudioSet\\'s features are zero-padded to make them the same length as CIFAR-100s.\", \"Table 4 shows the performance of FearNet for three separate training paradigms: 1) FearNet learns CIFAR-100 as the baseknowledge and then incrementally learns AudioSet; 2) FearNet learns AudioSet as the baseknowledge and then incrementally learns CIFAR-100; and 3) the base-knowledge contains a 50/50 split from both datasets with FearNet incrementally learning the remaining classes.\", \"Our results suggest FearNet is capable of incrementally learning multi-modal information, if the model has a good starting point (high base-knowledge); however, if the model starts with lower base-knowledge performance (e.g., AudioSet), the model struggles to learn new information incrementally (see Supplemental Material for detailed plots).Base-Knowledge Effect on Performance.\", \"In this section, we examine how the size of the baseknowledge (i.e., number of classes) affects FearNet\\'s performance on CUB-200.\", \"To do this, we varied the size of the base-knowledge from 10-150 classes, with the remaining classes learned incrementally.\", \"Detailed plots are provided in the Supplemental Material.\", \"As the base-knowledge size increases, there is a noticeable increase in overall model performance because 1) mPFC has a better learned representation from a larger quantity of data and 2) there are not as many incremental learning steps remaining for the dataset, so the base-knowledge performance is less perturbed.\", \"FearNet\\'s mPFC is trained to both discriminate examples and also generate new examples.\", \"While the main use of mPFC\\'s generative abilities is to enable psuedorehearsal, this ability may also help make the model more robust to catastrophic forgetting.\", \"BID18 observed that unsupervised networks are more robust (but not immune) to catastrophic forgetting because there are no target outputs to be forgotten.\", \"Since the pseudoexample generator is learned as a unsupervised reconstruction task, this could explain why FearNet is slow to forget old information.\", \"Table 5 : Memory requirements to train CIFAR-100 and the amount of memory that would be required if these models were trained up to 1,000 classes.\", \"Table 5 shows the memory requirements for each model in Sec. 6.1 for learning CIFAR-100 and a hypothetical extrapolation for learning 1,000 classes.\", \"This chart accounts for a fixed model capacity and storage of any data or class statistics.\", \"FearNet\\'s memory footprint is comparatively small because it only stores class statistics rather than some or all of the raw training data, which makes it better suited for deployment.\", \"An open question is how to deal with storage and updating of class statistics if classes are seen in more than one study sessions.\", \"One possibility is to use a running update for the class means and covariances, but it may be better to favor the data from the most recent study session due to learning in the autoencoder.\", \"FearNet assumed that the output of the mPFC encoder was normally distributed for each class, which may not be the case.\", \"It would be interesting to consider modeling the classes with a more complex model, e.g., a Gaussian Mixture Model.\", \"BID34 showed that pseudorehearsal worked reasonably well with randomly generated vectors because they were associated with the weights of a given class.\", \"Replaying these vectors strengthened their corresponding weights, which could be what is happening with the pseudo-examples generated by FearNet\\'s decoder.\", \"The largest impact on model size is the stored covariance matrix \\\\u03a3 c for each class.\", \"We tested a variant of FearNet that used a diagonal \\\\u03a3 c instead of a full covariance matrix.\", \"TAB5 shows that performance degrades, but FearNet still works.\", \"FearNet can be adapted to other paradigms, such as unsupervised learning and regression.\", \"For unsupervised learning, FearNet\\'s mPFC already does a form of it implicitly.\", \"For regression, this would require changing mPFC\\'s loss function and may require grouping input feature vectors into similar collections.\", \"FearNet could also be adapted to perform the supervised data permutation experiment performed by BID20 and BID24 .\", \"This would likely require storing statistics from previous permutations and classes.\", \"FearNet would sleep between learning different permutations; however, if the number of classes was high, recent recall may suffer.\", \"In this paper, we proposed a brain-inspired framework capable of incrementally learning data with different modalities and object classes.\", \"FearNet outperforms existing methods for incremental class learning on large image and audio classification benchmarks, demonstrating that FearNet is capable of recalling and consolidating recently learned information while also retaining old information.\", \"In addition, we showed that FearNet is more memory efficient, making it ideal for platforms where size, weight, and power requirements are limited.\", \"Future work will include 1) integrating BLA directly into the model (versus training it independently); 2) replacing HC with a semi-parametric model; 3) learning the feature embedding from raw inputs; and 4) replacing the pseduorehearsal mechanism with a generative model that does not require the storage of class statistics, which would be more memory efficient.\", \"A SUPPLEMENTAL MATERIAL A.1 MODEL HYPERPARAMETERS TAB1 shows the training parameters for the FearNet model for each dataset.\", \"We also experimented with various dropout rates, weight decay, and various activation functions; however, weight decay did not work well with FearNet\\'s mPFC.\", \"TAB1 : FearNet Training Parameters TAB2 shows the training parameters for the iCaRL framework used in this paper.\", \"We adapted the code from the author\\'s GitHub page for our own experiments.\", \"The ResNet-18 convolutional neural network was replaced with a fully-connected neural network.\", \"We experimented with various regularization strategies to increase the initial base-knowledge accuracy with weight decay working the best.\", \"The values that are given as a range of values are the hyperparameter search spaces.\", \"TAB9 shows the training parameters for GeppNet and GeppNet+STM.\", \"Parameters not listed here are the default parameters defined by BID17 .\", \"The values that are given as a range of values are the hyperparameter search spaces.\", \"A.3 BLA VARIANTS Our BLA model is a classifier that determines whether a prediction should be made using HC (recent memory) or mPFC (remote memory).\", \"An alternative approach would be to use an outlier detection algorithm that determines whether the data being processed by a sub-network is an outlier for that sub-network and should therefore be processed by the other sub-network.\", \"To explore this alternative BLA formulation, we experimented with three outlier detection algorithms: 1) one-class support vector machine (SVM) BID36 , 2) determining if the data fits into a Gaussian distribution using a minimum covariance determinant estimation (i.e., elliptical envelope) (Rousseeuw BID35 , and 3) the isolation forest BID27 .\", \"All three of these methods set a rejection criterion for if the test sample exists in HC; whereas the binary MLP reports a probability on how likely the test sample resides in HC.\", \"TAB5 : Performance of different BLA variants.\", \"Pseudocode for FearNet\\'s training and prediction algorithms are given in Algorithms 1 and 2 respectively.\", \"The variables match the ones defined in the paper.\", \"Algorithm 1: FearNet Training Data: X,y Classes/Study-Sessions: T; K: Sleep Frequency; Initialize mPFC with base-knowledge; Store \\\\u00b5 t , \\\\u03a3 t for each class in the base-knowledge; for c \\\\u2190 T /2 to T do Store X, y for class c in HC; if c % K == 0 then Fine-tune mPFC with X, y in HC and pseudoexamples generated by mPFC decoder; Update \\\\u00b5 t , \\\\u03a3 t for all classes seen so far; Clear HC; else Update BLA;Algorithm 2: FearNet Prediction Data: X A (X) \\\\u2190 P BLA (C = 1|X); \\\\u03c8 \\\\u2190 max k P HC (C=k|X)A(X) 1\\\\u2212A(X); if \\\\u03c8 > max k P mP F C (C = k|X) then return arg max k P HC (C = k |X); else return arg max k P mP F C (C = k |X);A.5 MULTI-MODAL LEARNING EXPERIMENT Fig. S1 shows the plots for the multi-modal experiments in Sec. 6.2.\", \"The three base-knowledge experiments were 1) CIFAR-100 is the base-knowledge and AudioSet is trained incrementally, 2) AudioSet is the base-knowledge and then AudioSet is trained incrementally, and 3) the base-knowledge is a 50/50 mix of the two datasets and then the remaining classes are trained incrementally.\", \"For all three base-knowledge experiments, we show the mean-class accuracy on the base-knowledge and the entire test set.\", \"FearNet works well when it adequately learns the base-knowledge (Experiment #1 and #3); however, when FearNet learns it poorly, incremental learning deteriorates.\", \"A.6 BASE-KNOWLEDGE EFFECT ON PERFORMANCE Figure S1 : Detailed plots for the multi-modal experiment.\", \"The top row is when the base-knowledge was CIFAR-100, the middle row is when the base-knowledge was AudioSet, and the bottom row is when the base-knowledge was a 50/50 mix from the two datasets.\", \"The left column represents the mean-class accuracy on the base-knowledge test set and the right column computes mean-class accuracy on the entire test set.remains relatively even because the size of the base-knowledge has no effect on the HC model\\'s ability to immediately recall new information; however, there is a very slight decrease that corresponds to the BLA model erroneously favoring mPFC in a few cases.\", \"Most importantly, \\\\u2126 all sees an increase in performance because; like \\\\u2126 base , there are not as many sleep phases to perturb older memories in mPFC.\"], \"source_labels\": [0, 0, 0, 0, 1, 0, 0, 0, 0], \"rouge_scores\": [0.285714281044898, 0.18181817681818196, 0.22727272227272738, 0.26666666275555556, 0.3243243195032871, 0.2799999950720001, 0.2499999957031251, 0.2926829218560381, 0.1999999950500001], \"paper_id\": \"SJ1Xmf-Rb\", \"target\": [\"FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.\", \"This paper presents a novel solution to an incremental classification problem based on a dual memory system. \"], \"title\": \"FearNet: Brain-Inspired Model for Incremental Learning\"}\\n'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17adb928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': ['Incremental class learning involves sequentially learning classes in bursts of examples from the same class.',\n",
       "  'This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.',\n",
       "  'Arguably, the best method for incremental class learning is iCaRL, but it requires storing  training examples for each class, making it challenging to scale.',\n",
       "  'Here, we propose FearNet for incremental class learning.',\n",
       "  'FearNet is a generative model that does not store previous examples, making it memory efficient.',\n",
       "  'FearNet uses a brain-inspired dual-memory system in which new memories are consolidated from a network for recent memories inspired by the mammalian hippocampal complex to a network for long-term storage inspired by medial prefrontal cortex.',\n",
       "  'Memory consolidation is inspired by mechanisms that occur during sleep.',\n",
       "  'FearNet also uses a module inspired by the basolateral amygdala for determining which memory system to use for recall.  ',\n",
       "  'FearNet achieves state-of-the-art performance at incremental class learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet) benchmarks.\\n',\n",
       "  'In incremental classification, an agent must sequentially learn to classify training examples, without necessarily having the ability to re-study previously seen examples.',\n",
       "  'While deep neural networks (DNNs) have revolutionized machine perception BID26 , off-the-shelf DNNs cannot incrementally learn classes due to catastrophic forgetting.',\n",
       "  'Catastrophic forgetting is a phenomenon in which a DNN completely fails to learn new data without forgetting much of its previously learned knowledge BID29 .',\n",
       "  'While methods have been developed to try and mitigate catastrophic forgetting, as shown in BID23 , these methods are not sufficient and perform poorly on larger datasets.',\n",
       "  'In this paper, we propose FearNet, a brain-inspired system for incrementally learning categories that significantly outperforms previous methods.',\n",
       "  'The standard way for dealing with catastrophic forgetting in DNNs is to avoid it altogether by mixing new training examples with old ones and completely re-training the model offline.',\n",
       "  'For large datasets, this may require weeks of time, and it is not a scalable solution.',\n",
       "  'An ideal incremental learning system would be able to assimilate new information without the need to store the entire training dataset.',\n",
       "  'A major application for incremental learning includes real-time operation on-board embedded platforms that have limited computing power, storage, and memory, e.g., smart toys, smartphone applications, and robots.',\n",
       "  'For example, a toy robot may need to learn to recognize objects within its local environment and of interest to its owner.',\n",
       "  'Using cloud computing to overcome these resource limitations may pose privacy risks and may not be scalable to a large number of embedded devices.',\n",
       "  'A better solution is on-device incremental learning, which requires the model to use less storage and computational power.',\n",
       "  'In this paper, we propose an incremental learning framework called FearNet (see Fig. 1 ).',\n",
       "  'FearNet has three brain-inspired sub-systems: 1) a recent memory system for quick recall, 2) a memory system for long-term storage, and 3) a sub-system that determines which memory system to use for a particular example.',\n",
       "  'FearNet mitigates catastrophic forgetting by consolidating recent memories into long-term storage using pseudorehearsal BID34 .',\n",
       "  'Pseudorehearsal allows the network to revisit previous memories during incremental training without the need to store previous training examples, which is more memory efficient.',\n",
       "  'Figure 1: FearNet consists of three braininspired modules based on 1) mPFC (longterm storage), 2) HC (recent storage), and 3) BLA for determining whether to use mPFC or HC for recall.',\n",
       "  'Problem Formulation:',\n",
       "  'Here, incremental class learning consists of T study-sessions.',\n",
       "  'At time t, the learner receives a batch of data B t , which contains N t labeled training samples, i.e., B t = {(x j , y j )} Nt j=1 , where x j ∈ R d is the input feature vector to be classified and y j is its corresponding label.',\n",
       "  'The number of training samples N t may vary between sessions, and the data inside a study-session is not assumed to be independent and identically distributed (iid).',\n",
       "  'During a study session, the learner only has access to its current batch, but it may use its own memory to store information from prior study sessions.',\n",
       "  'We refer to the first session as the model\\'s \"base-knowledge,\" which contains exemplars from M ≥ 1 classes.',\n",
       "  'The batches learned in all subsequent sessions contain only one class, i.e., all y j will be identical within those sessions.',\n",
       "  'Novel Contributions: Our contributions include:1.',\n",
       "  \"FearNet's architecture includes three neural networks: one inspired by the hippocampal complex (HC) for recent memories, one inspired by the medial prefrontal cortex (mPFC) for long-term storage, and one inspired by the basolateral amygdala (BLA) that determines whether to use HC or mPFC for recall.2.\",\n",
       "  'Motivated by memory replay during sleep, FearNet employs a generative autoencoder for pseudorehearsal, which mitigates catastrophic forgetting by generating previously learned examples that are replayed alongside novel information during consolidation.',\n",
       "  'This process does not involve storing previous training data.3.',\n",
       "  'FearNet achieves state-of-the-art results on large image and audio datasets with a relatively small memory footprint, demonstrating how dual-memory models can be scaled.',\n",
       "  'Catastrophic forgetting in DNNs occurs due to the plasticity-stability dilemma BID0 .',\n",
       "  'If the network is too plastic, older memories will quickly be overwritten; however, if the network is too stable, it is unable to learn new data.',\n",
       "  'This problem was recognized almost 30 years ago BID29 BID14 , methods developed in the 1980s and 1990s are extensively discussed, and French argued that mitigating catastrophic forgetting would require having two separate memory centers: one for the long-term storage of older memories and another to quickly process new information as it comes in.',\n",
       "  'He also theorized that this type of dual-memory system would be capable of consolidating memories from the fast learning memory center to longterm storage.',\n",
       "  'Catastrophic forgetting often occurs when a system is trained on non-iid data.',\n",
       "  'One strategy for reducing this phenomenon is to mix old examples with new examples, which simulates iid conditions.',\n",
       "  'For example, if the system learns ten classes in a study session and then needs to learn 10 new classes in a later study session, one solution could be to mix examples from the first study session into the later study session.',\n",
       "  'This method is known as rehearsal, and it is one of the earliest methods for reducing catastrophic forgetting BID22 .',\n",
       "  \"Rehearsal essentially uses an external memory to strengthen the model's representations for examples learned previously, so that they are not overwritten when learning data from new classes.\",\n",
       "  'Rehearsal reduces forgetting, but performance is still worse than offline models.',\n",
       "  'Moreover, rehearsal requires storing all of the training data.',\n",
       "  'BID34 argued that storing of training examples was inefficient and of \"little interest,\" so he introduced pseudorehearsal.',\n",
       "  'Rather than replaying past training data, in pseudorehearsal, the algorithm generates new examples for a given class.',\n",
       "  'In BID34 , this was done by creating random input vectors, having the network assign them a label, and then mixing them into the new training data.',\n",
       "  'This idea was revived in BID8 , where a generative autoencoder was used to create pseudo-examples for unsupervised incremental learning.',\n",
       "  \"This method inspired FearNet's approach to memory consolidation.\",\n",
       "  'Pseudorehearsal is related to memory replay that occurs in mammalian brains, which involves reactivation of recently encoded memories in HC so that they can be integrated into long-term storage in mPFC BID31 .Recently there has been renewed interest in solving catastrophic forgetting in supervised learning.',\n",
       "  'Many new methods are designed to mitigate catastrophic forgetting when each study session contains a permuted version of the entire training dataset (see BID20 ).',\n",
       "  'Unlike incremental class learning, all labels are contained in each study session.',\n",
       "  'PathNet uses an evolutionary algorithm to find the optimal path through a large DNN, and then freezes the weights along that path BID11 .',\n",
       "  'It assumes all classes are seen in each study session, and it is not capable of incremental class learning.',\n",
       "  'Elastic Weight Consolidation (EWC) employs a regularization scheme that redirects plasticity to the weights that are least important to previously learned study sessions BID24 .',\n",
       "  'After EWC learns a study session, it uses the training data to build a Fisher matrix that determines the importance of each feature to the classification task it just learned.',\n",
       "  'EWC was shown to work poorly at incremental class learning in BID23 .The Fixed Expansion Layer (FEL) model mitigates catastrophic forgetting by using sparse updates BID6 .',\n",
       "  'FEL uses two hidden layers, where the second hidden layer (i.e., the FEL layer) has connectivity constraints.',\n",
       "  'The FEL layer is much larger than the first hidden layer, is sparsely populated with excitatory and inhibitory weights, and is not updated during training.',\n",
       "  'This limits learning of dense shared representations, which reduces the risk of learning interfering with old memories.',\n",
       "  'FEL requires a large number of units to work well BID23 .',\n",
       "  \"Figure 2: iCaRL's performance depends heavily on the number of exemplars per class (EPC) that it stores.\",\n",
       "  'Reducing EPC from 20 (blue) to 1 (red) severely impairs its ability to recall older information.',\n",
       "  'Gepperth & Karaoguz (2016) introduced a new approach for incremental learning, which we call GeppNet.',\n",
       "  'GeppNet uses a self-organizing map (SOM) to reorganize the input onto a two-dimensional lattice.',\n",
       "  'This serves as a long-term memory, which is fed into a simple linear layer for classification.',\n",
       "  'After the SOM is initialized, it can only be updated if the input is sufficiently novel.',\n",
       "  'This prevents the model from forgetting older data too quickly.',\n",
       "  'GeppNet also uses rehearsal using all previous training data.',\n",
       "  'A variant of GeppNet, GeppNet+STM, uses a fixed-size memory buffer to store novel examples.',\n",
       "  'When this buffer is full, it replaces the oldest example.',\n",
       "  'During pre-defined intervals, the buffer is used to train the model.',\n",
       "  'GeppNet+STM is better at retaining base-knowledge since it only trains during its consolidation phase, but the STM-free version learns new data better because it updates the model on every novel labeled input.iCaRL BID33 is an incremental class learning framework.',\n",
       "  'Rather than directly using a DNN for classification, iCaRL uses it for supervised representation learning.',\n",
       "  \"During a study session, iCaRL updates a DNN using the study session's data and a set of J stored examples from earlier sessions (J = 2, 000 for CIFAR-100 in their paper), which is a kind of rehearsal.\",\n",
       "  'After a study session, the J examples retained are carefully chosen using herding.',\n",
       "  'After learning the entire dataset, iCaRL has retained J/T exemplars per class (e.g., J/T = 20 for CIFAR-100).',\n",
       "  'The DNN in iCaRL is then used to compute an embedding for each stored example, and then the mean embedding for each class seen is computed.',\n",
       "  'To classify a new instance, the DNN is used to compute an embedding for it, and then the class with the nearest mean embedding is assigned.',\n",
       "  \"iCaRL's performance is heavily influenced by the number of examples it stores, as shown in Fig. 2 .\",\n",
       "  'FearNet is heavily inspired by the dual-memory model of mammalian memory BID28 , which has considerable experimental support from neuroscience BID12 BID38 BID25 BID4 BID39 BID15 .',\n",
       "  'This theory proposes that HC and mPFC operate as complementary memory systems, where HC is responsible for recalling recent memories and mPFC is responsible for recalling remote (mature) memories.',\n",
       "  'GeppNet is the most recent DNN to be based on this theory, but it was also independently explored in the 1990s in French (1997) and BID3 .',\n",
       "  'In this section, we review some of the evidence for the dual-memory model.',\n",
       "  'One of the major reasons why HC is thought to be responsible for recent memories is that if HC is bilaterally destroyed, then anterograde amnesia occurs with old memories for semantic information preserved.',\n",
       "  'One mechanism HC may use to facilitate creating new memories is adult neurogenesis.',\n",
       "  \"This occurs in HC's dentate gyrus BID2 BID9 .\",\n",
       "  'The new neurons have higher initial plasticity, but it reduces as time progresses BID7 .In contrast, mPFC is responsible for the recall of remote (long-term) memories BID4 .',\n",
       "  'BID39 and BID15 showed that mPFC plays a strong role in memory consolidation during REM sleep.',\n",
       "  'BID28 and BID10 theorized that, during sleep, HC reactivates recent memories to prevent forgetting which causes these recent memories to replay in mPFC as well, with dreams possibly being caused by this process.',\n",
       "  'After memories are transferred from HC to mPFC, evidence suggests that corresponding memory in HC is erased (Poe, 2017).Recently, BID25 performed contextual fear conditioning (CFC) experiments in mice to trace the formation and consolidation of recent memories to long-term storage.',\n",
       "  'CFC experiments involve shocking mice while subjecting them to various visual stimuli (i.e., colored lights).',\n",
       "  \"They found that BLA, which is responsible for regulating the brain's fear response, would shift where it retrieved the corresponding memory from (HC or mPFC) as that memory was consolidated over time.\",\n",
       "  'FearNet follows the memory consolidation theory proposed by BID25 .',\n",
       "  'FearNet has two complementary memory centers, 1) a short-term memory system that immediately learns new information for recent recall (HC) and 2) a DNN for the storage of remote memories (mPFC).',\n",
       "  'FearNet also has a separate BLA network that determines which memory center contains the associated memory required for prediction.',\n",
       "  'During sleep phases, FearNet uses a generative model to consolidate data from HC to mPFC through pseudorehearsal.',\n",
       "  'Pseudocode for FearNet is provided in the supplemental material.',\n",
       "  'Because the focus of our work is not representation learning, we use pre-trained ResNet embeddings to obtain features that are fed to FearNet.',\n",
       "  \"FearNet's HC model is a variant of a probabilistic neural network BID37 .\",\n",
       "  'HC computes class conditional probabilities using stored training examples.',\n",
       "  \"Formally, HC estimates the probability that an input feature vector x belongs to class k as DISPLAYFORM0 (1) DISPLAYFORM1 where > 0 is a regularization parameter and u k,j is the j'th stored exemplar in HC for class k. All exemplars are removed from HC after they are consolidated into mPFC.FearNet's mPFC is implemented using a DNN trained both to reconstruct its input using a symmetric encoder-decoder (autoencoder) and to compute P mP F C (C = k|x).\",\n",
       "  'The autoencoder enables us to The mPFC and BLA sub-systems in FearNet.',\n",
       "  'mPFC is responsible for the long-term storage of remote memories.',\n",
       "  'BLA is used during prediction time to determine if the memory should be recalled from short-or long-term memory.use pseudorehearsal, which is described in more detail in Sec. 4.2.',\n",
       "  'The loss function for mPFC is DISPLAYFORM2 where L class is the supervised classification loss and L recon is the unsupervised reconstruction loss, as illustrated in FIG1 .',\n",
       "  'For L class , we use standard softmax loss.',\n",
       "  'L recon is the weighted sum of mean squared error (MSE) reconstruction losses from each layer, which is given by DISPLAYFORM3 where M is the number of mPFC layers, H j is the number of hidden units in layer j, h encoder,(i,j) and h decoder, (i,j) are the outputs of the encoder/decoder at layer j respectively, and λ j is the reconstruction weight for that layer.',\n",
       "  'mPFC is similar to a Ladder Network BID32 , which combines classification and reconstruction to improve regularization, especially during lowshot learning.',\n",
       "  'The λ j hyperparameters were found empirically, with λ 0 being largest and decreasing for deeper layers (see supplementary material).',\n",
       "  'This prioritizes the reconstruction task, which makes the generated pseudo-examples more realistic.',\n",
       "  'When training is completed during a study session, all of the data in HC is pushed through the encoder to extract a dense feature representation of the original data, and then we compute a mean feature vector µ c and covariance matrix Σ c for each class c. These are stored and used to generate pseudo-examples during consolidation (see Sec. 4.2).',\n",
       "  \"We study FearNet's performance as a function of how much data is stored in HC in Sec. 6.2.\",\n",
       "  \"During FearNet's sleep phase, the original inputs stored in HC are transferred to mPFC using pseudo-examples created by an autoencoder.\",\n",
       "  'This process is known as intrinsic replay, and it was used by Draelos et al. FORMULA1 for unsupervised learning.',\n",
       "  'Using the class statistics from the encoder, pseudo-examples for class c are generated by sampling a Gaussian with mean µ c and covariance matrix Σ c to obtainx rand .',\n",
       "  'Then,x rand is passed through the decoder to generate a pseudo-example.',\n",
       "  'To create a balanced training set, for each class that mPFC has learned, we generate m pseudo-examples, where m is the average number of examples per class stored in HC.',\n",
       "  'The pseudo-examples are mixed with the data in HC, and the mixture is used to fine-tune mPFC using backpropagation.',\n",
       "  'After consolidation, all units in HC are deleted.',\n",
       "  'During prediction, FearNet uses the BLA network ( FIG1 ) to determine whether to classify an input x using HC or mPFC.',\n",
       "  'This can be challenging because if HC has only been trained on one class, it will put all of its probability mass on that class, whereas mPFC will likely be less confident.',\n",
       "  'The output of BLA is given by A (x) and will be a value between 0 and 1, with a 1 indicating mPFC should be used.',\n",
       "  'BLA is trained after each study session using only the data in HC and with pseudoexamples generated with mPFC, using the same procedure described in Sec. 4.2.',\n",
       "  'Instead of using solely BLA to determine which network to use, we found that combining its output with those of mPFC and HC improved results.',\n",
       "  'The predicted classŷ is computed aŝ DISPLAYFORM0 where DISPLAYFORM1 ψ is the probability of the class according to HC weighted by the confidence that the associated memory is actually stored in HC.',\n",
       "  'BLA has the same number of layers/units as the mPFC encoder, and uses a logistic output unit.',\n",
       "  'We discuss alternative BLA models in supplemental material.',\n",
       "  'Evaluating Incremental Learning Performance.',\n",
       "  'To evaluate how well the incrementally trained models perform compared to an offline model, we use the three metrics proposed in BID23 .',\n",
       "  \"After each study session t in which a model learned a new class k, we compute the model's test accuracy on the new class (α new,t ), the accuracy on the base-knowledge (α base,t ), and the accuracy of all of the test data seen to this point (α all,t ).\",\n",
       "  \"After all T study sessions are complete, a model's ability to retain the base-knowledge is given by DISPLAYFORM0 , where α of f line is the accuracy of a multi-layer perceptron (MLP) trained offline (i.e., it is given all of the training data at once).\",\n",
       "  \"The model's ability to immediately recall new information is measured by and Ω all are relative to an offline MLP model, so a value of 1 indicates that a model has similar performance to the offline baseline.\",\n",
       "  'This allows results across datasets to be better compared.',\n",
       "  'Note that Ω base > 1 and Ω all > 1 only if the incremental learning algorithm is more accurate than the offline model, which can occur due to better regularization strategies employed by different models.',\n",
       "  'Datasets.',\n",
       "  'We evaluate all of the models on three benchmark datasets TAB1 : CIFAR-100, CUB-200, and AudioSet.',\n",
       "  'CIFAR-100 is a popular image classification dataset containing 100 mutually-exclusive object categories, and it was used in BID33 to evaluate iCaRL.',\n",
       "  'All images are 32 × 32 pixels.',\n",
       "  'CUB-200 is a fine-grained image classification dataset containing high resolution images of 200 different bird species BID40 .',\n",
       "  'We use the 2011 version of the dataset.',\n",
       "  'AudioSet is an audio classification dataset BID16 .',\n",
       "  'We use the variant of AudioSet used by BID23 , which contains a 100 class subset such that none of the classes were super-or sub-classes of one another.',\n",
       "  'Also, since the AudioSet data samples can have more than one class, the chosen samples had only one of the 100 classes chosen in this subset.',\n",
       "  'DISPLAYFORM1 For CIFAR-100 and CUB-200, we extract ResNet-50 image embeddings as the input to each of the models, where ResNet-50 was pre-trained on ImageNet BID21 .',\n",
       "  'We use the output after the mean pooling layer and normalize the features to unit length.',\n",
       "  'For AudioSet, we use the audio CNN embeddings produced by pre-training the model on the YouTube-8M dataset BID1 .',\n",
       "  'We use the pre-extracted AudioSet feature embeddings, which represent ten second sound clips (i.e., ten 128-dimensional vectors concatenated in order).Comparison Models.',\n",
       "  'We compare FearNet to FEL, GeppNet, GeppNet+STM, iCaRL, and an onenearest neighbor (1-NN).',\n",
       "  'FEL, GeppNet, and GeppNet+STM were chosen due to their previously reported efficacy at incremental class learning in BID23 .',\n",
       "  'iCARL is explicitly designed for incremental class learning, and represents the state-of-the-art on this problem.',\n",
       "  'We compare against 1-NN due to its similarity to our HC model.',\n",
       "  '1-NN does not forget any previously observed examples, but it tends to have worse generalization error than parametric methods and requires storing all of the training data.',\n",
       "  'In each of our experiments, all models take the same feature embedding as input for a given dataset.',\n",
       "  'This required modifying iCaRL by turning its CNN into a fully connected network.',\n",
       "  'We performed a hyperparameter search for each model/dataset combination to tune the number of units and layers (see Supplemental Materials).Training Parameters.',\n",
       "  'FearNet was implemented in Tensorflow.',\n",
       "  'For mPFC and BLA, each fully connected layer uses an exponential linear unit activation function BID5 .',\n",
       "  'The output of the encoder also connects to a softmax output layer.',\n",
       "  'Xavier initialization is used to initialize all weight layers BID19 , and all of the biases are initialized to one.',\n",
       "  \"BLA's architecture is identical to mPFC's encoder, except it has a logistic output unit, instead of a softmax layer.mPFC and BLA were trained using NAdam.\",\n",
       "  'We train mPFC on the base-knowledge set for 1,000 epochs, consolidate HC over to mPFC for 60 epochs, and train BLA for 20 epochs.',\n",
       "  \"Because mPFC's decoder is vital to preserving memories, its learning rate is 1/100 times lower than the encoder.\",\n",
       "  'We performed a hyperparameter search for each dataset and model, varying the model shape (64-1,024 units), depth (2-4 layers), and how often to sleep (see Sec. 6.2).',\n",
       "  'Across datasets, mPFC and BLA performed best with two hidden layers, but the number of units per layer varied across datasets.',\n",
       "  'The specific values used for each dataset are given in supplemental material.',\n",
       "  'In preliminary experiments, we found no benefit to adding weight decay to mPFC, likely because the reconstruction task helps regularize the model.',\n",
       "  'Unless otherwise noted, each class is only seen in one unique study-session and the first baseknowledge study session contains half the classes in the dataset.',\n",
       "  'We perform additional experiments to study how changing the number of base-knowledge classes affects performance in Sec. 6.2.',\n",
       "  'Unless otherwise noted, FearNet sleeps every 10 study sessions across datasets.',\n",
       "  'TAB2 shows incremental class learning summary results for all six methods.',\n",
       "  'FearNet achieves the best Ω base and Ω all on all three datasets.',\n",
       "  'FIG3 shows that FearNet more closely resembles the offline MLP baseline than other methods.',\n",
       "  'Ω new measures test accuracy on the most recently trained class.',\n",
       "  '1 For FearNet, this measures the performance of HC and BLA.',\n",
       "  'Ω new does not account for how well the class was consolidated into mPFC which happens later during a sleep phase; however, Ω all does account for this.',\n",
       "  'FEL achieves a high Ω new score because it is able to achieve nearly perfect test accuracy on every new class it learns, but this results in forgetting more quickly than FearNet.',\n",
       "  '1-NN is similar to our HC model; but on its own, it fails to generalize as well as FearNet, is memory inefficient, and is slow to make predictions.',\n",
       "  'The final mean-class test accuracy for the offline MLP used to normalize the metrics is 69.9% for CIFAR-100, 59.8% for CUB-200, and 45.8% for AudioSet.',\n",
       "  'Table 3 : FearNet performance when the location of the associated memory is known using an oracle versus using BLA.',\n",
       "  'Novelty Detection with BLA.',\n",
       "  'We evaluated the performance of BLA by comparing it to an oracle version of FearNet, i.e., a version that knew if the relevant memory was stored in either mPFC or HC.',\n",
       "  \"Table 3 shows that FearNet's BLA does a good job at predicting which network to use; however, the decrease in Ω new suggests BLA is sometimes using mPFC when it should be using HC.\",\n",
       "  'FIG5 , it is better able to retain its base-knowledge, but this reduces its ability to recall new information.',\n",
       "  'In humans, sleep deprivation is known to impair new learning BID41 , and that forgetting occurs during sleep BID30 .',\n",
       "  'Each time FearNet sleeps, the mPFC weights are perturbed which can cause it to gradually forget older memories.',\n",
       "  \"Sleeping less causes HC's recall performance to deteriorate.\",\n",
       "  'Table 4 : Multi-modal incremental learning experiment.',\n",
       "  'FearNet was trained with various base-knowledge sets (column-header) and then incrementally trained on all remaining data.',\n",
       "  'Multi-Modal Incremental Learning.',\n",
       "  'As shown in Sec. 6.1, FearNet can incrementally learn and retain information from a single dataset, but how does it perform if new inputs differ greatly from previously learned ones?',\n",
       "  'This scenario is one of the first shown to cause catastrophic forgetting in MLPs.',\n",
       "  'To study this, we trained FearNet to incrementally learn CIFAR-100 and AudioSet, which after training is a 200-way classification problem.',\n",
       "  \"To do this, AudioSet's features are zero-padded to make them the same length as CIFAR-100s.\",\n",
       "  'Table 4 shows the performance of FearNet for three separate training paradigms: 1) FearNet learns CIFAR-100 as the baseknowledge and then incrementally learns AudioSet; 2) FearNet learns AudioSet as the baseknowledge and then incrementally learns CIFAR-100; and 3) the base-knowledge contains a 50/50 split from both datasets with FearNet incrementally learning the remaining classes.',\n",
       "  'Our results suggest FearNet is capable of incrementally learning multi-modal information, if the model has a good starting point (high base-knowledge); however, if the model starts with lower base-knowledge performance (e.g., AudioSet), the model struggles to learn new information incrementally (see Supplemental Material for detailed plots).Base-Knowledge Effect on Performance.',\n",
       "  \"In this section, we examine how the size of the baseknowledge (i.e., number of classes) affects FearNet's performance on CUB-200.\",\n",
       "  'To do this, we varied the size of the base-knowledge from 10-150 classes, with the remaining classes learned incrementally.',\n",
       "  'Detailed plots are provided in the Supplemental Material.',\n",
       "  'As the base-knowledge size increases, there is a noticeable increase in overall model performance because 1) mPFC has a better learned representation from a larger quantity of data and 2) there are not as many incremental learning steps remaining for the dataset, so the base-knowledge performance is less perturbed.',\n",
       "  \"FearNet's mPFC is trained to both discriminate examples and also generate new examples.\",\n",
       "  \"While the main use of mPFC's generative abilities is to enable psuedorehearsal, this ability may also help make the model more robust to catastrophic forgetting.\",\n",
       "  'BID18 observed that unsupervised networks are more robust (but not immune) to catastrophic forgetting because there are no target outputs to be forgotten.',\n",
       "  'Since the pseudoexample generator is learned as a unsupervised reconstruction task, this could explain why FearNet is slow to forget old information.',\n",
       "  'Table 5 : Memory requirements to train CIFAR-100 and the amount of memory that would be required if these models were trained up to 1,000 classes.',\n",
       "  'Table 5 shows the memory requirements for each model in Sec. 6.1 for learning CIFAR-100 and a hypothetical extrapolation for learning 1,000 classes.',\n",
       "  'This chart accounts for a fixed model capacity and storage of any data or class statistics.',\n",
       "  \"FearNet's memory footprint is comparatively small because it only stores class statistics rather than some or all of the raw training data, which makes it better suited for deployment.\",\n",
       "  'An open question is how to deal with storage and updating of class statistics if classes are seen in more than one study sessions.',\n",
       "  'One possibility is to use a running update for the class means and covariances, but it may be better to favor the data from the most recent study session due to learning in the autoencoder.',\n",
       "  'FearNet assumed that the output of the mPFC encoder was normally distributed for each class, which may not be the case.',\n",
       "  'It would be interesting to consider modeling the classes with a more complex model, e.g., a Gaussian Mixture Model.',\n",
       "  'BID34 showed that pseudorehearsal worked reasonably well with randomly generated vectors because they were associated with the weights of a given class.',\n",
       "  \"Replaying these vectors strengthened their corresponding weights, which could be what is happening with the pseudo-examples generated by FearNet's decoder.\",\n",
       "  'The largest impact on model size is the stored covariance matrix Σ c for each class.',\n",
       "  'We tested a variant of FearNet that used a diagonal Σ c instead of a full covariance matrix.',\n",
       "  'TAB5 shows that performance degrades, but FearNet still works.',\n",
       "  'FearNet can be adapted to other paradigms, such as unsupervised learning and regression.',\n",
       "  \"For unsupervised learning, FearNet's mPFC already does a form of it implicitly.\",\n",
       "  \"For regression, this would require changing mPFC's loss function and may require grouping input feature vectors into similar collections.\",\n",
       "  'FearNet could also be adapted to perform the supervised data permutation experiment performed by BID20 and BID24 .',\n",
       "  'This would likely require storing statistics from previous permutations and classes.',\n",
       "  'FearNet would sleep between learning different permutations; however, if the number of classes was high, recent recall may suffer.',\n",
       "  'In this paper, we proposed a brain-inspired framework capable of incrementally learning data with different modalities and object classes.',\n",
       "  'FearNet outperforms existing methods for incremental class learning on large image and audio classification benchmarks, demonstrating that FearNet is capable of recalling and consolidating recently learned information while also retaining old information.',\n",
       "  'In addition, we showed that FearNet is more memory efficient, making it ideal for platforms where size, weight, and power requirements are limited.',\n",
       "  'Future work will include 1) integrating BLA directly into the model (versus training it independently); 2) replacing HC with a semi-parametric model; 3) learning the feature embedding from raw inputs; and 4) replacing the pseduorehearsal mechanism with a generative model that does not require the storage of class statistics, which would be more memory efficient.',\n",
       "  'A SUPPLEMENTAL MATERIAL A.1 MODEL HYPERPARAMETERS TAB1 shows the training parameters for the FearNet model for each dataset.',\n",
       "  \"We also experimented with various dropout rates, weight decay, and various activation functions; however, weight decay did not work well with FearNet's mPFC.\",\n",
       "  'TAB1 : FearNet Training Parameters TAB2 shows the training parameters for the iCaRL framework used in this paper.',\n",
       "  \"We adapted the code from the author's GitHub page for our own experiments.\",\n",
       "  'The ResNet-18 convolutional neural network was replaced with a fully-connected neural network.',\n",
       "  'We experimented with various regularization strategies to increase the initial base-knowledge accuracy with weight decay working the best.',\n",
       "  'The values that are given as a range of values are the hyperparameter search spaces.',\n",
       "  'TAB9 shows the training parameters for GeppNet and GeppNet+STM.',\n",
       "  'Parameters not listed here are the default parameters defined by BID17 .',\n",
       "  'The values that are given as a range of values are the hyperparameter search spaces.',\n",
       "  'A.3 BLA VARIANTS Our BLA model is a classifier that determines whether a prediction should be made using HC (recent memory) or mPFC (remote memory).',\n",
       "  'An alternative approach would be to use an outlier detection algorithm that determines whether the data being processed by a sub-network is an outlier for that sub-network and should therefore be processed by the other sub-network.',\n",
       "  'To explore this alternative BLA formulation, we experimented with three outlier detection algorithms: 1) one-class support vector machine (SVM) BID36 , 2) determining if the data fits into a Gaussian distribution using a minimum covariance determinant estimation (i.e., elliptical envelope) (Rousseeuw BID35 , and 3) the isolation forest BID27 .',\n",
       "  'All three of these methods set a rejection criterion for if the test sample exists in HC; whereas the binary MLP reports a probability on how likely the test sample resides in HC.',\n",
       "  'TAB5 : Performance of different BLA variants.',\n",
       "  \"Pseudocode for FearNet's training and prediction algorithms are given in Algorithms 1 and 2 respectively.\",\n",
       "  'The variables match the ones defined in the paper.',\n",
       "  'Algorithm 1: FearNet Training Data: X,y Classes/Study-Sessions: T; K: Sleep Frequency; Initialize mPFC with base-knowledge; Store µ t , Σ t for each class in the base-knowledge; for c ← T /2 to T do Store X, y for class c in HC; if c % K == 0 then Fine-tune mPFC with X, y in HC and pseudoexamples generated by mPFC decoder; Update µ t , Σ t for all classes seen so far; Clear HC; else Update BLA;Algorithm 2: FearNet Prediction Data: X A (X) ← P BLA (C = 1|X); ψ ← max k P HC (C=k|X)A(X) 1−A(X); if ψ > max k P mP F C (C = k|X) then return arg max k P HC (C = k |X); else return arg max k P mP F C (C = k |X);A.5 MULTI-MODAL LEARNING EXPERIMENT Fig. S1 shows the plots for the multi-modal experiments in Sec. 6.2.',\n",
       "  'The three base-knowledge experiments were 1) CIFAR-100 is the base-knowledge and AudioSet is trained incrementally, 2) AudioSet is the base-knowledge and then AudioSet is trained incrementally, and 3) the base-knowledge is a 50/50 mix of the two datasets and then the remaining classes are trained incrementally.',\n",
       "  'For all three base-knowledge experiments, we show the mean-class accuracy on the base-knowledge and the entire test set.',\n",
       "  'FearNet works well when it adequately learns the base-knowledge (Experiment #1 and #3); however, when FearNet learns it poorly, incremental learning deteriorates.',\n",
       "  'A.6 BASE-KNOWLEDGE EFFECT ON PERFORMANCE Figure S1 : Detailed plots for the multi-modal experiment.',\n",
       "  'The top row is when the base-knowledge was CIFAR-100, the middle row is when the base-knowledge was AudioSet, and the bottom row is when the base-knowledge was a 50/50 mix from the two datasets.',\n",
       "  \"The left column represents the mean-class accuracy on the base-knowledge test set and the right column computes mean-class accuracy on the entire test set.remains relatively even because the size of the base-knowledge has no effect on the HC model's ability to immediately recall new information; however, there is a very slight decrease that corresponds to the BLA model erroneously favoring mPFC in a few cases.\",\n",
       "  'Most importantly, Ω all sees an increase in performance because; like Ω base , there are not as many sleep phases to perturb older memories in mPFC.'],\n",
       " 'source_labels': [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'rouge_scores': [0.285714281044898,\n",
       "  0.18181817681818196,\n",
       "  0.22727272227272738,\n",
       "  0.26666666275555556,\n",
       "  0.3243243195032871,\n",
       "  0.2799999950720001,\n",
       "  0.2499999957031251,\n",
       "  0.2926829218560381,\n",
       "  0.1999999950500001],\n",
       " 'paper_id': 'SJ1Xmf-Rb',\n",
       " 'target': ['FearNet is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.',\n",
       "  'This paper presents a novel solution to an incremental classification problem based on a dual memory system. '],\n",
       " 'title': 'FearNet: Brain-Inspired Model for Incremental Learning'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = json.loads(lines[0])\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292bb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_sample in test_sample['target']:\n",
    "    if target_sample in test_sample['source']:\n",
    "        print(target_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356750bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental class learning involves sequentially learning classes in bursts of examples from the same class. This violates the assumptions that underlie  methods for training standard deep neural networks, and will cause them to suffer from catastrophic forgetting.\n"
     ]
    }
   ],
   "source": [
    "summarizer = SingleLangSummarizer(ft_en)\n",
    "print(summarizer.summarize(' '.join(test_sample['source']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54848d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 13:55:17.627847: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# flask==2.0.1\n",
    "# flask_socketio==5.1.1\n",
    "# simple-websocket==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "727a6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 558.32 MiB (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to /home/anton/tensorflow_datasets/cnn_dailymail/3.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de99ba470ea948e2b038e10d38a6adbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b81e0032534651bd7673d48ce48833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3243943910475c97d852a10d25f877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cnn_dailymail-train.tfrecord...:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cnn_dailymail-validation.tfrecord...:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cnn_dailymail-test.tfrecord...:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cnn_dailymail downloaded and prepared to /home/anton/tensorflow_datasets/cnn_dailymail/3.1.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 14:10:22.544657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-11 14:10:22.582802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-11 14:10:22.583235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Laptop GPU computeCapability: 8.6\n",
      "coreClock: 1.245GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 357.69GiB/s\n",
      "2021-08-11 14:10:22.583254: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-08-11 14:10:22.600636: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-08-11 14:10:22.600674: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-08-11 14:10:22.605962: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-11 14:10:22.607936: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-11 14:10:22.609548: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-08-11 14:10:22.613219: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-08-11 14:10:22.613308: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-08-11 14:10:22.613317: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-11 14:10:22.613926: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-11 14:10:22.614727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-11 14:10:22.614735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{Split('train'): <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>,\n",
       " Split('validation'): <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>,\n",
       " Split('test'): <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56249c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops. Outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch. In one instance, the complaint alleges, Mata arranged to pay two assassins to kill rival drug dealers. The killers would pose as cops, pulling over their targets before shooting them, according to the complaint. \"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement. The complaint also alleges that Mata used his police badge to purchase weapons for drug traffickers. Mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic. Court documents released by investigators do not specify the name of the drug trafficking organization with which Mata allegedly conspired but says the organization has been importing narcotics from places such as Ecuador and the Dominican Republic by hiding them \"inside shipping containers containing pallets of produce, including bananas.\" The organization \"has been distributing narcotics in New Jersey and elsewhere,\" the complaint says. Authorities arrested Mata on Tuesday in Miami Gardens, Florida. It was not immediately clear whether Mata has an attorney, and police officials could not be immediately reached for comment. Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint. Since March 2010, he had been working in the internal affairs division. Mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. He is scheduled to appear in federal court in Florida on Wednesday. If convicted, Mata could face life in prison. CNN's Suzanne Presto contributed to this report.\n",
      "---------\n",
      "Criminal complaint: Cop used his role to help cocaine traffickers .\n",
      "Ralph Mata, an internal affairs lieutenant, allegedly helped group get guns .\n",
      "He also arranged to pay two assassins in a murder plot, a complaint alleges .\n"
     ]
    }
   ],
   "source": [
    "# test_dataset = tf.data.Dataset.from_tensor_slices(list(ds['test']))\n",
    "print(train_list[1]['article'].numpy().decode('utf-8'))\n",
    "print('---------')\n",
    "print(train_list[1]['highlights'].numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e52dbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb0bd3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: sentences:\n",
      "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops.\n",
      "Outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns.\n",
      "A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch.\n",
      "In one instance, the complaint alleges, Mata arranged to pay two assassins to kill rival drug dealers.\n",
      "The killers would pose as cops, pulling over their targets before shooting them, according to the complaint.\n",
      "\"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement.\n",
      "The complaint also alleges that Mata used his police badge to purchase weapons for drug traffickers.\n",
      "Mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
      "Court documents released by investigators do not specify the name of the drug trafficking organization with which Mata allegedly conspired but says the organization has been importing narcotics from places such as Ecuador and the Dominican Republic by hiding them \"inside shipping containers containing pallets of produce, including bananas.\"\n",
      "The organization \"has been distributing narcotics in New Jersey and elsewhere,\" the complaint says.\n",
      "Authorities arrested Mata on Tuesday in Miami Gardens, Florida.\n",
      "It was not immediately clear whether Mata has an attorney, and police officials could not be immediately reached for comment.\n",
      "Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint.\n",
      "Since March 2010, he had been working in the internal affairs division.\n",
      "Mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity.\n",
      "He is scheduled to appear in federal court in Florida on Wednesday.\n",
      "If convicted, Mata could face life in prison.\n",
      "CNN's Suzanne Presto contributed to this report.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch. \"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement. Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db336260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: sentences:\n",
      "By .\n",
      "Associated Press .\n",
      "PUBLISHED: .\n",
      "14:11 EST, 25 October 2013 .\n",
      "| .\n",
      "UPDATED: .\n",
      "15:36 EST, 25 October 2013 .\n",
      "The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October.\n",
      "The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion.\n",
      "Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A .\n",
      "State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure.\n",
      "The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A.\n",
      "The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month.\n",
      "Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort.\n",
      "Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
      "--------------------------------------------------\n",
      "Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
      "--------------------------------------------------\n",
      "Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\n",
      "He contracted the infection through contaminated food in Italy .\n",
      "Church members in Fargo, Grand Forks and Jamestown could have been exposed .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.6060606060606061,\n",
       "   'p': 0.46511627906976744,\n",
       "   'f': 0.5263157845602493},\n",
       "  'rouge-2': {'r': 0.3939393939393939, 'p': 0.25, 'f': 0.3058823481910035},\n",
       "  'rouge-l': {'r': 0.5757575757575758,\n",
       "   'p': 0.4418604651162791,\n",
       "   'f': 0.4999999950865652}}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_0 = train_list[0]\n",
    "hyp0 = summarizer.summarize(text_0['article'].numpy().decode('utf-8'), k=3)\n",
    "ref0 = text_0['highlights'].numpy().decode('utf-8')\n",
    "print('-' * 50)\n",
    "print(hyp0)\n",
    "print('-' * 50)\n",
    "print(ref0)\n",
    "rouge.get_scores(hyp0, ref0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "620ca0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: sentences:\n",
      "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops.\n",
      "Outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns.\n",
      "A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch.\n",
      "In one instance, the complaint alleges, Mata arranged to pay two assassins to kill rival drug dealers.\n",
      "The killers would pose as cops, pulling over their targets before shooting them, according to the complaint.\n",
      "\"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement.\n",
      "The complaint also alleges that Mata used his police badge to purchase weapons for drug traffickers.\n",
      "Mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic.\n",
      "Court documents released by investigators do not specify the name of the drug trafficking organization with which Mata allegedly conspired but says the organization has been importing narcotics from places such as Ecuador and the Dominican Republic by hiding them \"inside shipping containers containing pallets of produce, including bananas.\"\n",
      "The organization \"has been distributing narcotics in New Jersey and elsewhere,\" the complaint says.\n",
      "Authorities arrested Mata on Tuesday in Miami Gardens, Florida.\n",
      "It was not immediately clear whether Mata has an attorney, and police officials could not be immediately reached for comment.\n",
      "Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint.\n",
      "Since March 2010, he had been working in the internal affairs division.\n",
      "Mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity.\n",
      "He is scheduled to appear in federal court in Florida on Wednesday.\n",
      "If convicted, Mata could face life in prison.\n",
      "CNN's Suzanne Presto contributed to this report.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.3333333333333333,\n",
       "   'p': 0.13580246913580246,\n",
       "   'f': 0.19298245202677755},\n",
       "  'rouge-2': {'r': 0.11764705882352941,\n",
       "   'p': 0.0380952380952381,\n",
       "   'f': 0.057553953139071724},\n",
       "  'rouge-l': {'r': 0.3333333333333333,\n",
       "   'p': 0.13580246913580246,\n",
       "   'f': 0.19298245202677755}}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1 = train_list[1]\n",
    "hyp1 = summarizer.summarize(text_1['article'].numpy().decode('utf-8'), k=3)\n",
    "ref1 = text_1['highlights'].numpy().decode('utf-8')\n",
    "rouge.get_scores(hyp1, ref1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8655f4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.4696969696969697,\n",
       "  'p': 0.30045937410278495,\n",
       "  'f': 0.3596491182935134},\n",
       " 'rouge-2': {'r': 0.2557932263814617,\n",
       "  'p': 0.14404761904761904,\n",
       "  'f': 0.18171815066503763},\n",
       " 'rouge-l': {'r': 0.4545454545454546,\n",
       "  'p': 0.2888314671260408,\n",
       "  'f': 0.3464912235566714}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores([hyp0, hyp1], [ref0, ref1], avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cb990",
   "metadata": {},
   "source": [
    "## Evaluating SingleLangSummarizer (no stopwords removal, no lemmatizing) with FastText english model on cnn_dailymail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a2e92",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2ec7c8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 20:07:39.801410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-21 20:07:39.854460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-08-21 20:07:39.854513: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-21 20:07:39.855851: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>,\n",
       " 'validation': <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>,\n",
       " 'test': <PrefetchDataset shapes: {article: (), highlights: ()}, types: {article: tf.string, highlights: tf.string}>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting dataset\n",
    "ds, ds_info = tfds.load('cnn_dailymail', with_info=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac4edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing summarizer\n",
    "summarizer = SingleLangSummarizer(ft_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167a08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function for evaluation\n",
    "def evaluate_cnn_dailymail(summarizer, data, k: int = 3):\n",
    "    hyps, refs = [], []\n",
    "    for sample in tqdm(data):\n",
    "        text = sample['article'].numpy().decode('utf-8')\n",
    "        ref = sample['highlights'].numpy().decode('utf-8')\n",
    "        hyp = summarizer.summarize(text, k)\n",
    "        hyps.append(hyp)\n",
    "        refs.append(ref)\n",
    "    print(json.dumps(rouge.get_scores(hyps, refs, avg=True), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758ea922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 15:55:57.209068: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-11 15:55:57.228297: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
      "  1%|▋                                                                       | 2772/287113 [07:43<13:11:35,  5.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9088/814340623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_cnn_dailymail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9088/2979973242.py\u001b[0m in \u001b[0;36mevaluate_cnn_dailymail\u001b[0;34m(summarizer, data, k)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'highlights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mhyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mhyps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9088/1093383447.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(self, text, k)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m#         print(*sentences, sep='\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentence_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_similarity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mnx_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagerank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9088/1093383447.py\u001b[0m in \u001b[0;36m_get_similarity_matrix\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1902\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'%d' is not a supported axis\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001b[0m\u001b[1;32m   1905\u001b[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[1;32m   1906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'fc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \"\"\"\n\u001b[1;32m    686\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2242\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/interviews/aspose/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[1;32m     72\u001b[0m                   if v is not np._NoValue}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "evaluate_cnn_dailymail(summarizer, list(ds['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d822f02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation\n",
    "val = list(ds['validation'])\n",
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b5b3ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 13368/13368 [26:40<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rouge-1\": {\n",
      "        \"r\": 0.34489054437451205,\n",
      "        \"p\": 0.22542288039598582,\n",
      "        \"f\": 0.26357269051841586\n",
      "    },\n",
      "    \"rouge-2\": {\n",
      "        \"r\": 0.10720480599459638,\n",
      "        \"p\": 0.065581516534886,\n",
      "        \"f\": 0.07804714178094152\n",
      "    },\n",
      "    \"rouge-l\": {\n",
      "        \"r\": 0.310961474565765,\n",
      "        \"p\": 0.2031631889617812,\n",
      "        \"f\": 0.2375559584110965\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluate_cnn_dailymail(summarizer, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb68886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11490"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "test = list(ds['test'])\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f18d91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11490/11490 [23:22<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"rouge-1\": {\n",
      "        \"r\": 0.34512175359695446,\n",
      "        \"p\": 0.21787056480942532,\n",
      "        \"f\": 0.25846525347495475\n",
      "    },\n",
      "    \"rouge-2\": {\n",
      "        \"r\": 0.1057098270264606,\n",
      "        \"p\": 0.062296011345463614,\n",
      "        \"f\": 0.07507965718344696\n",
      "    },\n",
      "    \"rouge-l\": {\n",
      "        \"r\": 0.31091823545802955,\n",
      "        \"p\": 0.1962828177921399,\n",
      "        \"f\": 0.23280499034968744\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluate_cnn_dailymail(summarizer, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ffa7c",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "# Training only on CnnDailymail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f448c9",
   "metadata": {},
   "source": [
    "## CnnDailymail analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878fe0ff",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### In the following cells we analyze lengths of sentences and documents to understand how our model should look like\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a5d363f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 47/287113 [00:00<20:44, 230.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 15\n",
      "current min(sentences_count): 15\n",
      "current max(words_count): 36\n",
      "current min(words_count): 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                      | 10041/287113 [00:45<20:26, 225.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 209\n",
      "current min(sentences_count): 3\n",
      "current max(words_count): 791\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████                                                                    | 20043/287113 [01:29<20:30, 216.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 255\n",
      "current min(sentences_count): 3\n",
      "current max(words_count): 791\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                 | 30025/287113 [02:14<18:59, 225.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 255\n",
      "current min(sentences_count): 3\n",
      "current max(words_count): 791\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▏                                                              | 40035/287113 [02:59<17:08, 240.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 304\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▋                                                            | 50050/287113 [03:43<16:37, 237.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 352\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▎                                                         | 60024/287113 [04:30<19:23, 195.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 352\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████▊                                                       | 70031/287113 [05:17<17:49, 203.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 352\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▎                                                    | 80035/287113 [06:04<16:20, 211.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 352\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████▉                                                  | 90031/287113 [06:50<14:05, 233.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 352\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████                                               | 100034/287113 [07:37<14:06, 220.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████▌                                            | 110047/287113 [08:23<13:09, 224.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████                                          | 120033/287113 [09:10<14:34, 191.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████▌                                       | 130046/287113 [09:57<11:36, 225.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████                                     | 140040/287113 [10:44<11:09, 219.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████▌                                  | 150028/287113 [11:31<10:44, 212.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████▏                               | 160071/287113 [12:18<09:22, 226.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████▋                             | 170035/287113 [13:05<09:28, 206.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████▏                          | 180032/287113 [13:52<08:11, 217.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████████████▋                        | 190033/287113 [14:39<07:50, 206.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████▏                     | 200026/287113 [15:25<06:24, 226.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████▋                   | 210029/287113 [16:11<05:54, 217.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████████████████▏                | 220046/287113 [16:58<05:07, 217.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████▋              | 230033/287113 [17:44<04:31, 210.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████▏           | 240023/287113 [18:31<03:41, 213.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████▋         | 250032/287113 [19:18<02:50, 216.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████▏      | 260048/287113 [20:05<02:00, 225.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████▋    | 270040/287113 [20:51<01:30, 188.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████▏ | 280052/287113 [21:38<00:30, 229.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current max(sentences_count): 399\n",
      "current min(sentences_count): 1\n",
      "current max(words_count): 1746\n",
      "current min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 287113/287113 [22:11<00:00, 215.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(sentences_count): 399\n",
      "min(sentences_count): 1\n",
      "max(words_count): 1746\n",
      "min(words_count): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_texts_properties(dataset: List[Dict]) -> Set[int]:\n",
    "    # words_count = set()\n",
    "    # sentences_count = set()\n",
    "    words_count = defaultdict(int)\n",
    "    sentences_count = defaultdict(int)\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        e = train[i]\n",
    "        text = e['article'].numpy().decode('utf-8')\n",
    "        sentences = sent_tokenize(text.replace('\\n', ' ').strip())\n",
    "        # sentences_count.add(len(sentences))\n",
    "        sentences_count[len(sentences)] += 1\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            # res = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "            # words_count.add(len(words))\n",
    "            words_count[len(words)] += 1\n",
    "        if i % 10000 == 0:\n",
    "            print(f'current max(sentences_count): {max(sentences_count.keys())}')\n",
    "            print(f'current min(sentences_count): {min(sentences_count.keys())}')\n",
    "            print(f'current max(words_count): {max(words_count.keys())}')\n",
    "            print(f'current min(words_count): {min(words_count.keys())}')\n",
    "    return words_count, sentences_count\n",
    "\n",
    "words_count, sentences_count = get_texts_properties(train)\n",
    "print(f'max(sentences_count): {max(sentences_count.keys())}')\n",
    "print(f'min(sentences_count): {min(sentences_count.keys())}')\n",
    "print(f'max(words_count): {max(words_count.keys())}')\n",
    "print(f'min(words_count): {min(words_count.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce5add46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences_count[201]\n",
    "words_count[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab402869",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAI/CAYAAAAm37dDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4t0lEQVR4nO3df6xm910f+PendhwQv+wkU8vymI5bZkEGCSdMHSNoRWNij5OKMauAHFVklnWZVjiroHYLE1Za04SsnF2VlEjglamnmSCK4wYiW9hgRk66CGmdeEJMEjtkfXEc2SPHnmYcB5olrMNn/7jfIY8n987MHd/nPvfe83pJj55zPud7zvnec57net4+53xvdXcAAADY/v7OojsAAADAxhAAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIkQAAEAACbi/EV3YL296lWv6l27di26GwAAAAvx8Y9//L92946Vlm27ALhr164cPXp00d0AAABYiKr6/GrL3AIKAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMxlwBYVd9dVQ/PvL5cVT9XVa+oqiNV9dh4v2i0r6p6b1UtVdUnq+o1M9vaP9o/VlX759FfAACAKZhLAOzuz3b3ld19ZZIfSPKVJB9KcjDJA929O8kDYz5Jrk+ye7wOJLktSarqFUluSfLaJFclueVkaAQAAGBtNuIW0GuS/Hl3fz7JviSHR/1wkhvG9L4k7+9lDya5sKouSXJdkiPdfaK7n0tyJMneDegzAADAtrMRAfDGJL89pi/u7qfH9BeSXDymL03y5Mw6T43aanXmbNfBexfdBQAAYJ3NNQBW1QVJfizJfz51WXd3kl6n/RyoqqNVdfT48ePrsUkAAIBtZ95XAK9P8ifd/cyYf2bc2pnx/uyoH0ty2cx6O0dttfqLdPft3b2nu/fs2LFjnX8EAACA7WHeAfDN+frtn0lyT5KTI3nuT3L3TP0tYzTQq5M8P24VvT/JtVV10Rj85dpRAwAAYI3mFgCr6luSvD7J786Ub03y+qp6LMmPjvkkuS/J40mWkvxGkp9Nku4+keSdSR4ar3eMGnPi2T8AANi+zp/Xhrv7vyV55Sm1L2Z5VNBT23aSm1fZzqEkh+bRRwAAgCnZiFFA2QZcGQQAgK1PAAQAAJgIAZBz4oogAABsPQIgayL4AQDA1jW3QWDYWgQ7AADY/lwB5LTOJhjuOnivAAkAAFuAAAgAADARAiAAAMBEeAaQc+a2TwAA2FpcAQQAAJgIARAAAGAiBEAAAICJEAABAAAmwiAwE7eeA7mc3NYTt75x3bYJAACsH1cAAQAAJsIVwInyJxwAAGB6XAEEAACYCAEQAABgIgRA1t2ug/e6xRQAADYhARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgRAAACAiZhbAKyqC6vqg1X1Z1X1mar6wap6RVUdqarHxvtFo21V1XuraqmqPllVr5nZzv7R/rGq2j+v/gIAAGx387wC+KtJ/qC7vyfJ9yf5TJKDSR7o7t1JHhjzSXJ9kt3jdSDJbUlSVa9IckuS1ya5KsktJ0Mjm5+/BwgAAJvLXAJgVX1Hkn+c5I4k6e6/7u4vJdmX5PBodjjJDWN6X5L397IHk1xYVZckuS7Jke4+0d3PJTmSZO88+gwAALDdnT+n7V6e5HiS/1hV35/k40neluTi7n56tPlCkovH9KVJnpxZ/6lRW63OOXJFDgAApmtet4Cen+Q1SW7r7lcn+W/5+u2eSZLu7iS9HjurqgNVdbSqjh4/fnw9NgkAALDtzCsAPpXkqe7+6Jj/YJYD4TPj1s6M92fH8mNJLptZf+eorVZ/ke6+vbv3dPeeHTt2rOsPAgAAsF3MJQB29xeSPFlV3z1K1yR5NMk9SU6O5Lk/yd1j+p4kbxmjgV6d5Plxq+j9Sa6tqovG4C/XjhoAAABrNK9nAJPkf0ryW1V1QZLHk/x0lgPnXVV1U5LPJ/nJ0fa+JG9IspTkK6NtuvtEVb0zyUOj3Tu6+8Qc+wwAALBtzS0AdvfDSfassOiaFdp2kptX2c6hJIfWtXMTZPAXAABgnn8HEAAAgE1EAAQAAJgIAZC5c/spAABsDgIgAADARAiAbBhXAgEAYLEEQAAAgIkQAAEAACZCAAQAAJgIAXACPHsHAAAkAiAAAMBkCIAAAAATIQACAABMhAAIAAAwEQIgG+7koDQGpwEAgI0lAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMhAAIAAAwEQIgAADARAiA29hW+Tt7W6WfAACw1QmAAAAAEyEAAgAATMTcAmBVPVFVn6qqh6vq6Ki9oqqOVNVj4/2iUa+qem9VLVXVJ6vqNTPb2T/aP1ZV++fVXwAAgO1u3lcA/0l3X9nde8b8wSQPdPfuJA+M+SS5Psnu8TqQ5LZkOTAmuSXJa5NcleSWk6ERAACAtdnoW0D3JTk8pg8nuWGm/v5e9mCSC6vqkiTXJTnS3Se6+7kkR5Ls3eA+AwAAbAvzDICd5A+r6uNVdWDULu7up8f0F5JcPKYvTfLkzLpPjdpqdQAAANbo/Dlu+4e7+1hV/d0kR6rqz2YXdndXVa/HjkbAPJAk3/md37kemwQAANh25nYFsLuPjfdnk3woy8/wPTNu7cx4f3Y0P5bkspnVd47aavVT93V7d+/p7j07duxY7x9ly9mKf1dv18F7t2S/AQBgK5lLAKyqb6mqbzs5neTaJJ9Ock+SkyN57k9y95i+J8lbxmigVyd5ftwqen+Sa6vqojH4y7WjBgAAwBrN6xbQi5N8qKpO7uM/dfcfVNVDSe6qqpuSfD7JT4729yV5Q5KlJF9J8tNJ0t0nquqdSR4a7d7R3Sfm1GcAAIBtbS4BsLsfT/L9K9S/mOSaFeqd5OZVtnUoyaH17iMAAMDUbPSfgQAAAGBBBEAAAICJEADZVIwGCgAA8yMAAgAATIQACAAAMBECIAAAwEQIgAAAABMhALIpGQwGAADWnwAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIJua0UABAGD9CIAAAAATIQBuI66UAQAApyMAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAMiW4O8BAgDASycAAgAATIQACAAAMBECIAAAwETMLQBW1XlV9Ymq+r0xf3lVfbSqlqrqA1V1wai/fMwvjeW7Zrbx9lH/bFVdN6++AgAATME8rwC+LclnZubfneQ93f1dSZ5LctOo35TkuVF/z2iXqroiyY1JvjfJ3iS/XlXnzbG/AAAA29pcAmBV7UzyxiT/YcxXktcl+eBocjjJDWN635jPWH7NaL8vyZ3d/dXu/lySpSRXzaO/AAAAUzCvK4D/PsnPJ/mbMf/KJF/q7hfG/FNJLh3TlyZ5MknG8udH+7+tr7AOM/x5BAAA4GysewCsqn+a5Nnu/vh6b/s0+zxQVUer6ujx48c3arcAAABbyjyuAP5Qkh+rqieS3JnlWz9/NcmFVXX+aLMzybExfSzJZUkyln9Hki/O1ldY50W6+/bu3tPde3bs2LG+Pw0AAMA2se4BsLvf3t07u3tXlgdx+XB3/7MkH0nyptFsf5K7x/Q9Yz5j+Ye7u0f9xjFK6OVJdif52Hr3l61l18F73fIKAADn6PwzN1k3v5Dkzqr65SSfSHLHqN+R5DerainJiSyHxnT3I1V1V5JHk7yQ5Obu/toG9hcAAGBbmWsA7O7/kuS/jOnHs8Iont39V0l+YpX135XkXfPrIQAAwHTM8+8Awty4DRQAANZOAAQAAJgIAZAtzZVAAAA4ewIgAADARAiAAAAAEyEAAgAATMRG/h1A1pnn3wAAgLVwBRAAAGAiBEAAAICJEAABAAAmQgBkW/A8JAAAnJkACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQCyrfh7gAAAsDoBkG1JEAQAgG8kAAIAAEyEAAgAADARAiAAAMBECIAAAAATMZcAWFXfVFUfq6o/rapHqurfjvrlVfXRqlqqqg9U1QWj/vIxvzSW75rZ1ttH/bNVdd08+sv2tOvgvQaDAQCAGfO6AvjVJK/r7u9PcmWSvVV1dZJ3J3lPd39XkueS3DTa35TkuVF/z2iXqroiyY1JvjfJ3iS/XlXnzanPAAAA29pcAmAv+8sx+7Lx6iSvS/LBUT+c5IYxvW/MZyy/pqpq1O/s7q929+eSLCW5ah59BgAA2O7On9eGx5W6jyf5riS/luTPk3ypu18YTZ5KcumYvjTJk0nS3S9U1fNJXjnqD85sdnadyXJb49qcPF5P3PrGBfcEAAAWa26DwHT317r7yiQ7s3zV7nvmta+qOlBVR6vq6PHjx+e1GwAAgC1t7qOAdveXknwkyQ8mubCqTl513Jnk2Jg+luSyJBnLvyPJF2frK6wzu4/bu3tPd+/ZsWPHPH4MAACALW9eo4DuqKoLx/Q3J3l9ks9kOQi+aTTbn+TuMX3PmM9Y/uHu7lG/cYwSenmS3Uk+No8+AwAAbHfzegbwkiSHx3OAfyfJXd39e1X1aJI7q+qXk3wiyR2j/R1JfrOqlpKcyPLIn+nuR6rqriSPJnkhyc3d/bU59RkAAGBbm0sA7O5PJnn1CvXHs8Iont39V0l+YpVtvSvJu9a7jwAAAFMz92cAAQAA2BwEQCZj18F7/QkNAAAmTQAEAACYCAEQAABgIuY1Cihz4PbF9XHyOD5x6xsX3BMAANhYrgACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQAyGT5w/AAAEyNAAgAADARAiAAAMBECIBMnltBAQCYCgEQAABgIgRAGFwFBABguxMAAQAAJkIABAAAmAgBEAAAYCIEQDiFZwEBANiuBEAAAICJEAABAAAmQgAEAACYCAEQVuFZQAAAtpu5BMCquqyqPlJVj1bVI1X1tlF/RVUdqarHxvtFo15V9d6qWqqqT1bVa2a2tX+0f6yq9s+jvwAAAFMwryuALyT51919RZKrk9xcVVckOZjkge7eneSBMZ8k1yfZPV4HktyWLAfGJLckeW2Sq5LccjI0wkZxJRAAgO1iLgGwu5/u7j8Z03+R5DNJLk2yL8nh0exwkhvG9L4k7+9lDya5sKouSXJdkiPdfaK7n0tyJMneefQZAABgu5v7M4BVtSvJq5N8NMnF3f30WPSFJBeP6UuTPDmz2lOjtlodAACANZprAKyqb03yO0l+rru/PLusuztJr9N+DlTV0ao6evz48fXYJAAAwLYztwBYVS/Lcvj7re7+3VF+ZtzamfH+7KgfS3LZzOo7R221+ot09+3dvae79+zYsWN9fxAAAIBt4vx5bLSqKskdST7T3b8ys+ieJPuT3Dre756pv7Wq7szygC/Pd/fTVXV/kv9tZuCXa5O8fR593swMQrI5zJ6HJ2594wJ7AgAA52YuATDJDyX5qSSfqqqHR+0Xsxz87qqqm5J8PslPjmX3JXlDkqUkX0ny00nS3Seq6p1JHhrt3tHdJ+bUZwAAgG1tLgGwu/84Sa2y+JoV2neSm1fZ1qEkh9avdwAAANM091FAAQAA2BwEQDgHuw7e69lMAAC2HAEQAABgIgRAAACAiRAAAQAAJkIAhJfAs4AAAGwlAiCsA0EQAICtQAAEAACYCAEQAABgIgRAWEduBQUAYDMTAAEAACZCAIQ5cCUQAIDNSAAEAACYCAEQ5shVQAAANhMBEAAAYCIEQAAAgIkQAGEDuBUUAIDN4PxFd4DVCQ0AAMB6cgUQAABgIgRA2EAnr+q6ugsAwCIIgLBAgiAAABtJAAQAAJgIARAWbNfBe10JBABgQwiAAAAAEyEAwibhSiAAAPM2lwBYVYeq6tmq+vRM7RVVdaSqHhvvF416VdV7q2qpqj5ZVa+ZWWf/aP9YVe2fR19hsxEEAQCYl3ldAXxfkr2n1A4meaC7dyd5YMwnyfVJdo/XgSS3JcuBMcktSV6b5Kokt5wMjQAAAKzdXAJgd/9RkhOnlPclOTymDye5Yab+/l72YJILq+qSJNclOdLdJ7r7uSRH8o2hEgAAgLN0/gbu6+LufnpMfyHJxWP60iRPzrR7atRWq8MknHob6BO3vnFBPQEAYLtYyCAw3d1Jer22V1UHqupoVR09fvz4em0WAABgW9nIAPjMuLUz4/3ZUT+W5LKZdjtHbbX6N+ju27t7T3fv2bFjx7p3HDYDg8MAAPBSbWQAvCfJyZE89ye5e6b+ljEa6NVJnh+3it6f5NqqumgM/nLtqAEAAHAO5vVnIH47yf+d5Lur6qmquinJrUleX1WPJfnRMZ8k9yV5PMlSkt9I8rNJ0t0nkrwzyUPj9Y5Rg0lzFRAAgHM1l0FguvvNqyy6ZoW2neTmVbZzKMmhdewabBu7Dt5rYBgAANZkI0cB5Sy5wgMAAMzDQkYBBdaP/2EAAMDZEgBhmxAEAQA4EwEQAABgIgRA2Ib8zUAAAFYiAMI2Mxv8BEEAAGYJgDABgiAAAIkACJMiCAIATJsACAAAMBH+EDxM2OzVwCdufeMCewIAwEYQAGGC3AYKADBNbgHdZPzDnEXy+QMA2N4EQOAbCIIAANuTAAis6mQQFAgBALYHARAAAGAiDAIDnJXVrgIaPRQAYOtwBRBYF/7IPADA5icAAi/JasFPGAQA2HwEQGBdnRoIBUEAgM1DANwk/COZ7e7UEUVPBkWffQCAjSMAAgsnCAIAbAwBENh0VruNVEgEAHhpBEBg01gp+J0u9J26TEAEADg9ARDYck4X/GafLVxtdFJBEQCYqk0fAKtqb1V9tqqWqurgovuz3vxDFOZrtUB4NreVCosAwHZz/qI7cDpVdV6SX0vy+iRPJXmoqu7p7kcX2zNgu9l18N48cesbX/Q+u+x0nrj1jatu4+QyAIDNYFMHwCRXJVnq7seTpKruTLIvyZYPgP5hCNvHmQLiSqFyLfyuAADWy2YPgJcmeXJm/qkkr11QXwAWZrWriy8lVJ7uiuWp2xVCAWB7qO5edB9WVVVvSrK3u//5mP+pJK/t7ree0u5AkgNj9ruTfHZDO3pmr0ryXxfdiYly7BfL8V8cx35xHPvFcvwXx7FfLMd/cTbjsf973b1jpQWb/QrgsSSXzczvHLUX6e7bk9y+UZ1aq6o62t17Ft2PKXLsF8vxXxzHfnEc+8Vy/BfHsV8sx39xttqx3+yjgD6UZHdVXV5VFyS5Mck9C+4TAADAlrSprwB29wtV9dYk9yc5L8mh7n5kwd0CAADYkjZ1AEyS7r4vyX2L7sdLtGlvT50Ax36xHP/FcewXx7FfLMd/cRz7xXL8F2dLHftNPQgMAAAA62ezPwMIAADAOhEA56iq9lbVZ6tqqaoOLro/U1BVT1TVp6rq4ao6OmqvqKojVfXYeL9o0f3cDqrqUFU9W1WfnqmteKxr2XvHd+GTVfWaxfV8e1jl+P9SVR0bn/+Hq+oNM8vePo7/Z6vqusX0enuoqsuq6iNV9WhVPVJVbxt1n/85O82x99nfAFX1TVX1sar603H8/+2oX15VHx3H+QNj4L5U1cvH/NJYvmuhP8AWdppj/76q+tzMZ//KUfd7Z51V1XlV9Ymq+r0xv2U/9wLgnFTVeUl+Lcn1Sa5I8uaqumKxvZqMf9LdV84Mx3swyQPdvTvJA2Oel+59SfaeUlvtWF+fZPd4HUhy2wb1cTt7X77x+CfJe8bn/8rxDHXG754bk3zvWOfXx+8ozs0LSf51d1+R5OokN49j7PM/f6sd+8RnfyN8Ncnruvv7k1yZZG9VXZ3k3Vk+/t+V5LkkN432NyV5btTfM9pxblY79knyb2Y++w+Pmt876+9tST4zM79lP/cC4PxclWSpux/v7r9OcmeSfQvu01TtS3J4TB9OcsPiurJ9dPcfJTlxSnm1Y70vyft72YNJLqyqSzako9vUKsd/NfuS3NndX+3uzyVZyvLvKM5Bdz/d3X8ypv8iy/8guDQ+/3N3mmO/Gp/9dTQ+w385Zl82Xp3kdUk+OOqnfvZPfic+mOSaqqqN6e32cppjvxq/d9ZRVe1M8sYk/2HMV7bw514AnJ9Lkzw5M/9UTv8fKdZHJ/nDqvp4VR0YtYu7++kx/YUkFy+ma5Ow2rH2fdg4bx23+xyqr9/u7PjPybi159VJPhqf/w11yrFPfPY3xLgN7uEkzyY5kuTPk3ypu18YTWaP8d8e/7H8+SSv3NAObyOnHvvuPvnZf9f47L+nql4+aj776+vfJ/n5JH8z5l+ZLfy5FwDZbn64u1+T5Vsfbq6qfzy7sJeHvTX07QZwrBfitiT/IMu3Bz2d5N8ttDfbXFV9a5LfSfJz3f3l2WU+//O1wrH32d8g3f217r4yyc4sX039nsX2aDpOPfZV9X1J3p7lc/APk7wiyS8srofbU1X90yTPdvfHF92X9SIAzs+xJJfNzO8cNeaou4+N92eTfCjL/3F65uRtD+P92cX1cNtb7Vj7PmyA7n5m/APhb5L8Rr5+q5vjv86q6mVZDiC/1d2/O8o+/xtgpWPvs7/xuvtLST6S5AezfHvhyb8tPXuM//b4j+XfkeSLG9vT7Wfm2O8dt0V3d381yX+Mz/48/FCSH6uqJ7L8SNfrkvxqtvDnXgCcn4eS7B4jBF2Q5YfQ71lwn7a1qvqWqvq2k9NJrk3y6Swf9/2j2f4kdy+mh5Ow2rG+J8lbxqhkVyd5fuZWOdbJKc93/HiWP//J8vG/cYxMdnmWBwX42Eb3b7sYz3LckeQz3f0rM4t8/udstWPvs78xqmpHVV04pr85yeuz/BzmR5K8aTQ79bN/8jvxpiQfbn+A+pyscuz/bOZ/OlWWn0Gb/ez7vbMOuvvt3b2zu3dl+d/zH+7uf5Yt/Lk//8xNOBfd/UJVvTXJ/UnOS3Koux9ZcLe2u4uTfGg8Z3t+kv/U3X9QVQ8luauqbkry+SQ/ucA+bhtV9dtJfiTJq6rqqSS3JLk1Kx/r+5K8IcsDMHwlyU9veIe3mVWO/4+MIcA7yRNJ/kWSdPcjVXVXkkezPIrizd39tQV0e7v4oSQ/leRT43mcJPnF+PxvhNWO/Zt99jfEJUkOj5FU/06Su7r796rq0SR3VtUvJ/lElkN6xvtvVtVSlgetunERnd4mVjv2H66qHUkqycNJ/uVo7/fO/P1CtujnvjZZIAUAAGBO3AIKAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBEnL/oDqy3V73qVb1r165FdwMAAGAhPv7xj//X7t6x0rJtFwB37dqVo0ePLrobAAAAC1FVn19tmVtAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIkQAAEAACZCAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgDcILsO3rvoLgAAABMnAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBFnHQCr6ryq+kRV/d6Yv7yqPlpVS1X1gaq6YNRfPuaXxvJdM9t4+6h/tqqum6nvHbWlqjo4U19xHwAAAKzdWq4Avi3JZ2bm353kPd39XUmeS3LTqN+U5LlRf89ol6q6IsmNSb43yd4kvz5C5XlJfi3J9UmuSPLm0fZ0+9gWdh28d9FdAAAAJuSsAmBV7UzyxiT/YcxXktcl+eBocjjJDWN635jPWH7NaL8vyZ3d/dXu/lySpSRXjddSdz/e3X+d5M4k+86wDwAAANbobK8A/vskP5/kb8b8K5N8qbtfGPNPJbl0TF+a5MkkGcufH+3/tn7KOqvVT7cPAAAA1uiMAbCq/mmSZ7v74xvQn3NSVQeq6mhVHT1+/PiiuwMAALApnc0VwB9K8mNV9USWb898XZJfTXJhVZ0/2uxMcmxMH0tyWZKM5d+R5Iuz9VPWWa3+xdPs40W6+/bu3tPde3bs2HEWPxIAAMD0nDEAdvfbu3tnd+/K8iAuH+7uf5bkI0neNJrtT3L3mL5nzGcs/3B396jfOEYJvTzJ7iQfS/JQkt1jxM8Lxj7uGeustg8AAADW6KX8HcBfSPKvqmopy8/r3THqdyR55aj/qyQHk6S7H0lyV5JHk/xBkpu7+2vjGb+3Jrk/y6OM3jXanm4fAAAArNH5Z27ydd39X5L8lzH9eJZH8Dy1zV8l+YlV1n9XknetUL8vyX0r1FfcBwAAAGv3Uq4AAgAAsIUIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMxBkDYFV9U1V9rKr+tKoeqap/O+rvq6rPVdXD43XlqFdVvbeqlqrqk1X1mplt7a+qx8Zr/0z9B6rqU2Od91ZVjforqurIaH+kqi5a9yMAAAAwEWdzBfCrSV7X3d+f5Moke6vq6rHs33T3leP18Khdn2T3eB1IcluyHOaS3JLktUmuSnLLTKC7LcnPzKy3d9QPJnmgu3cneWDMbzu7Dt676C4AAAATcMYA2Mv+csy+bLz6NKvsS/L+sd6DSS6sqkuSXJfkSHef6O7nkhzJcpi8JMm3d/eD3d1J3p/khpltHR7Th2fqAAAArNFZPQNYVedV1cNJns1yiPvoWPSucZvne6rq5aN2aZInZ1Z/atROV39qhXqSXNzdT4/pLyS5+Kx+KgAAAL7BWQXA7v5ad1+ZZGeSq6rq+5K8Pcn3JPmHSV6R5Bfm1cnRh84qVx6r6kBVHa2qo8ePH59nN+bGbaAAAMC8rWkU0O7+UpKPJNnb3U+P2zy/muQ/Zvm5viQ5luSymdV2jtrp6jtXqCfJM+MW0Yz3Z1fp1+3dvae79+zYsWMtPxIAAMBknM0ooDuq6sIx/c1JXp/kz2aCWWX52bxPj1XuSfKWMRro1UmeH7dx3p/k2qq6aAz+cm2S+8eyL1fV1WNbb0ly98y2To4Wun+mDgAAwBqdfxZtLklyuKrOy3JgvKu7f6+qPlxVO5JUkoeT/MvR/r4kb0iylOQrSX46Sbr7RFW9M8lDo907uvvEmP7ZJO9L8s1Jfn+8kuTWJHdV1U1JPp/kJ8/x5wQAAJi8MwbA7v5kklevUH/dKu07yc2rLDuU5NAK9aNJvm+F+heTXHOmPgIAAHBma3oGEAAAgK1LAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgRAAACAiRAAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIkQAAEAACZCAFyQXQfvXXQXAACAiREAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIk4YwCsqm+qqo9V1Z9W1SNV9W9H/fKq+mhVLVXVB6rqglF/+ZhfGst3zWzr7aP+2aq6bqa+d9SWqurgTH3FfQAAALB2Z3MF8KtJXtfd35/kyiR7q+rqJO9O8p7u/q4kzyW5abS/Kclzo/6e0S5VdUWSG5N8b5K9SX69qs6rqvOS/FqS65NckeTNo21Osw8AAADW6IwBsJf95Zh92Xh1ktcl+eCoH05yw5jeN+Yzll9TVTXqd3b3V7v7c0mWklw1Xkvd/Xh3/3WSO5PsG+ustg8AAADW6KyeARxX6h5O8mySI0n+PMmXuvuF0eSpJJeO6UuTPJkkY/nzSV45Wz9lndXqrzzNPgAAAFijswqA3f217r4yyc4sX7H7nnl2aq2q6kBVHa2qo8ePH190dwAAADalNY0C2t1fSvKRJD+Y5MKqOn8s2pnk2Jg+luSyJBnLvyPJF2frp6yzWv2Lp9nHqf26vbv3dPeeHTt2rOVHAgAAmIyzGQV0R1VdOKa/Ocnrk3wmy0HwTaPZ/iR3j+l7xnzG8g93d4/6jWOU0MuT7E7ysSQPJdk9Rvy8IMsDxdwz1lltHwAAAKzR+WdukkuSHB6jdf6dJHd19+9V1aNJ7qyqX07yiSR3jPZ3JPnNqlpKciLLgS7d/UhV3ZXk0SQvJLm5u7+WJFX11iT3JzkvyaHufmRs6xdW2QcAAABrdMYA2N2fTPLqFeqPZ/l5wFPrf5XkJ1bZ1ruSvGuF+n1J7jvbfWxnuw7emydufeOiuwEAAGxDa3oGEAAAgK1LAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAFwAXYdvHfRXQAAACZIAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgRAAACAiRAANyF/JxAAAJgHARAAAGAiBEAAAICJEAABAAAmQgAEAACYiDMGwKq6rKo+UlWPVtUjVfW2Uf+lqjpWVQ+P1xtm1nl7VS1V1Wer6rqZ+t5RW6qqgzP1y6vqo6P+gaq6YNRfPuaXxvJd6/rTAwAATMjZXAF8Icm/7u4rklyd5OaqumIse093Xzle9yXJWHZjku9NsjfJr1fVeVV1XpJfS3J9kiuSvHlmO+8e2/quJM8luWnUb0ry3Ki/Z7QDAADgHJwxAHb30939J2P6L5J8Jsmlp1llX5I7u/ur3f25JEtJrhqvpe5+vLv/OsmdSfZVVSV5XZIPjvUPJ7lhZluHx/QHk1wz2gMAALBGa3oGcNyC+eokHx2lt1bVJ6vqUFVdNGqXJnlyZrWnRm21+iuTfKm7Xzil/qJtjeXPj/YAAACs0VkHwKr61iS/k+TnuvvLSW5L8g+SXJnk6ST/bh4dPMu+Haiqo1V19Pjx44vqBgAAwKZ2VgGwql6W5fD3W939u0nS3c9099e6+2+S/EaWb/FMkmNJLptZfeeorVb/YpILq+r8U+ov2tZY/h2j/Yt09+3dvae79+zYseNsfiQAAIDJOZtRQCvJHUk+092/MlO/ZKbZjyf59Ji+J8mNYwTPy5PsTvKxJA8l2T1G/LwgywPF3NPdneQjSd401t+f5O6Zbe0f029K8uHRHgAAgDU6/8xN8kNJfirJp6rq4VH7xSyP4nllkk7yRJJ/kSTd/UhV3ZXk0SyPIHpzd38tSarqrUnuT3JekkPd/cjY3i8kubOqfjnJJ7IcODPef7OqlpKcyHJoBAAA4BycMQB29x8nWWnkzftOs867krxrhfp9K63X3Y/n67eQztb/KslPnKmPAAAAnNmaRgEFAABg6xIAAQAAJkIA3KR2Hbx30V0AAAC2GQEQAABgIgRAAACAiRAAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIkQAAEAACZCAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgTADbbr4L2L7gIAADBRAiAAAMBECIAAAAATccYAWFWXVdVHqurRqnqkqt426q+oqiNV9dh4v2jUq6reW1VLVfXJqnrNzLb2j/aPVdX+mfoPVNWnxjrvrao63T4AAABYu7O5AvhCkn/d3VckuTrJzVV1RZKDSR7o7t1JHhjzSXJ9kt3jdSDJbclymEtyS5LXJrkqyS0zge62JD8zs97eUV9tHwAAAKzRGQNgdz/d3X8ypv8iyWeSXJpkX5LDo9nhJDeM6X1J3t/LHkxyYVVdkuS6JEe6+0R3P5fkSJK9Y9m3d/eD3d1J3n/KtlbaBwAAAGu0pmcAq2pXklcn+WiSi7v76bHoC0kuHtOXJnlyZrWnRu109adWqOc0+wAAAGCNzjoAVtW3JvmdJD/X3V+eXTau3PU69+1FTrePqjpQVUer6ujx48fn2Q0AAIAt66wCYFW9LMvh77e6+3dH+Zlx+2bG+7OjfizJZTOr7xy109V3rlA/3T5epLtv7+493b1nx44dZ/MjAQAATM7ZjAJaSe5I8pnu/pWZRfckOTmS5/4kd8/U3zJGA706yfPjNs77k1xbVReNwV+uTXL/WPblqrp67Ostp2xrpX0AAACwRuefRZsfSvJTST5VVQ+P2i8muTXJXVV1U5LPJ/nJsey+JG9IspTkK0l+Okm6+0RVvTPJQ6PdO7r7xJj+2STvS/LNSX5/vHKafQAAALBGZwyA3f3HSWqVxdes0L6T3LzKtg4lObRC/WiS71uh/sWV9gEAAMDarWkUUAAAALYuARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgRAAACAiRAAAQAAJkIABAAAmAgBEAAAYCIEQAAAgIkQAAEAACZCAAQAAJgIARAAAGAiBMANtOvgvYvuAgAAMGECIAAAwEQIgJucq4YAAMB6EQABAAAm4owBsKoOVdWzVfXpmdovVdWxqnp4vN4ws+ztVbVUVZ+tqutm6ntHbamqDs7UL6+qj476B6rqglF/+ZhfGst3rdtPDQAAMEFncwXwfUn2rlB/T3dfOV73JUlVXZHkxiTfO9b59ao6r6rOS/JrSa5PckWSN4+2SfLusa3vSvJckptG/aYkz436e0Y7AAAAztEZA2B3/1GSE2e5vX1J7uzur3b355IsJblqvJa6+/Hu/uskdybZV1WV5HVJPjjWP5zkhpltHR7TH0xyzWgPAADAOXgpzwC+tao+OW4RvWjULk3y5Eybp0Zttfork3ypu184pf6ibY3lz4/2AAAAnINzDYC3JfkHSa5M8nSSf7deHToXVXWgqo5W1dHjx48vsisAAACb1jkFwO5+pru/1t1/k+Q3snyLZ5IcS3LZTNOdo7Za/YtJLqyq80+pv2hbY/l3jPYr9ef27t7T3Xt27NhxLj8SAADAtndOAbCqLpmZ/fEkJ0cIvSfJjWMEz8uT7E7ysSQPJdk9Rvy8IMsDxdzT3Z3kI0neNNbfn+TumW3tH9NvSvLh0R4AAIBzcP6ZGlTVbyf5kSSvqqqnktyS5Eeq6sokneSJJP8iSbr7kaq6K8mjSV5IcnN3f21s561J7k9yXpJD3f3I2MUvJLmzqn45ySeS3DHqdyT5zapayvIgNDe+1B8WAABgys4YALv7zSuU71ihdrL9u5K8a4X6fUnuW6H+eL5+C+ls/a+S/MSZ+gcAAMDZeSmjgAIAALCFCIAAAAATIQACAABMhAAIAAAwEQLgFrDr4L2L7gIAALANCIAAAAATIQACAABMhAAIAAAwEQIgAADARAiAAAAAEyEAAgAATIQACAAAMBECIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIAAAAATIQACAABMxBkDYFUdqqpnq+rTM7VXVNWRqnpsvF806lVV762qpar6ZFW9Zmad/aP9Y1W1f6b+A1X1qbHOe6uqTrcPAAAAzs3ZXAF8X5K9p9QOJnmgu3cneWDMJ8n1SXaP14EktyXLYS7JLUlem+SqJLfMBLrbkvzMzHp7z7APAAAAzsEZA2B3/1GSE6eU9yU5PKYPJ7lhpv7+XvZgkgur6pIk1yU50t0nuvu5JEeS7B3Lvr27H+zuTvL+U7a10j4AAAA4B+f6DODF3f30mP5CkovH9KVJnpxp99Sona7+1Ar10+0DAACAc/CSB4EZV+56HfpyzvuoqgNVdbSqjh4/fnyeXQEAANiyzjUAPjNu38x4f3bUjyW5bKbdzlE7XX3nCvXT7eMbdPft3b2nu/fs2LHjHH8kAACA7e1cA+A9SU6O5Lk/yd0z9beM0UCvTvL8uI3z/iTXVtVFY/CXa5PcP5Z9uaquHqN/vuWUba20DwAAAM7B+WdqUFW/neRHkryqqp7K8mietya5q6puSvL5JD85mt+X5A1JlpJ8JclPJ0l3n6iqdyZ5aLR7R3efHFjmZ7M80ug3J/n98cpp9gEAAMA5OGMA7O43r7LomhXadpKbV9nOoSSHVqgfTfJ9K9S/uNI+AAAAODcveRAYAAAAtgYBEAAAYCIEQAAAgIkQAAEAACZCAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgDcQnYdvHfRXQAAALYwARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIgRAAACAiRAAAQAAJkIABAAAmAgBEAAAYCJeUgCsqieq6lNV9XBVHR21V1TVkap6bLxfNOpVVe+tqqWq+mRVvWZmO/tH+8eqav9M/QfG9pfGuvVS+rsd7Dp476K7AAAAbFHrcQXwn3T3ld29Z8wfTPJAd+9O8sCYT5Lrk+werwNJbkuWA2OSW5K8NslVSW45GRpHm5+ZWW/vOvQXAABgkuZxC+i+JIfH9OEkN8zU39/LHkxyYVVdkuS6JEe6+0R3P5fkSJK9Y9m3d/eD3d1J3j+zLQAAANbopQbATvKHVfXxqjowahd399Nj+gtJLh7TlyZ5cmbdp0btdPWnVqgDAABwDs5/iev/cHcfq6q/m+RIVf3Z7MLu7qrql7iPMxrh80CSfOd3fue8dwcAALAlvaQrgN19bLw/m+RDWX6G75lx+2bG+7Oj+bEkl82svnPUTlffuUJ9pX7c3t17unvPjh07XsqPBAAAsG2dcwCsqm+pqm87OZ3k2iSfTnJPkpMjee5PcveYvifJW8ZooFcneX7cKnp/kmur6qIx+Mu1Se4fy75cVVeP0T/fMrMtAAAA1uilXAG8OMkfV9WfJvlYknu7+w+S3Jrk9VX1WJIfHfNJcl+Sx5MsJfmNJD+bJN19Isk7kzw0Xu8YtYw2/2Gs8+dJfv8l9Hfb8KcgAACAc3HOzwB29+NJvn+F+heTXLNCvZPcvMq2DiU5tEL9aJLvO9c+AgAA8HXz+DMQAAAAbEICIAAAwEQIgAAAABMhAAIAAEyEAAgAADARAiAAAMBECIBblL8FCAAArJUACAAAMBECIAAAwEQIgFuY20ABAIC1EAABAAAmQgAEAACYCAEQAABgIgTALc5zgAAAwNkSAAEAACZCAAQAAJgIARAAAGAiBMBtwrOAAADAmQiA24gQCAAAnM6mD4BVtbeqPltVS1V1cNH9AQAA2Ko2dQCsqvOS/FqS65NckeTNVXXFYnu1+bkSCAAArGRTB8AkVyVZ6u7Hu/uvk9yZZN+C+7Ql7Dp4ryAIAAC8yPmL7sAZXJrkyZn5p5K8dkF92bJOBsEnbn3jN4TCJ2594yK6BAAALEB196L7sKqqelOSvd39z8f8TyV5bXe/9ZR2B5IcGLPfneSzG9rRs/OqJP910Z1gTZyzrcc523qcs63HOdt6nLOtxznbWjbj+fp73b1jpQWb/QrgsSSXzczvHLUX6e7bk9y+UZ06F1V1tLv3LLofnD3nbOtxzrYe52zrcc62Huds63HOtpatdr42+zOADyXZXVWXV9UFSW5Mcs+C+wQAALAlbeorgN39QlW9Ncn9Sc5Lcqi7H1lwtwAAALakTR0Ak6S770ty36L7sQ429S2qrMg523qcs63HOdt6nLOtxznbepyzrWVLna9NPQgMAAAA62ezPwMIAADAOhEA56yq9lbVZ6tqqaoOLro/LKuqy6rqI1X1aFU9UlVvG/VfqqpjVfXweL1hZp23j/P42aq6bnG9n66qeqKqPjXOzdFRe0VVHamqx8b7RaNeVfXecc4+WVWvWWzvp6eqvnvmu/RwVX25qn7O92xzqapDVfVsVX16prbm71VV7R/tH6uq/Yv4WaZilXP2f1TVn43z8qGqunDUd1XV/zvzffs/Z9b5gfE7dWmc11rAjzMJq5yzNf8u9O/KjbPKOfvAzPl6oqoeHvWt9T3rbq85vbI8cM2fJ/n7SS5I8qdJrlh0v7w6SS5J8pox/W1J/p8kVyT5pST/8wrtrxjn7+VJLh/n9bxF/xxTeyV5IsmrTqn970kOjumDSd49pt+Q5PeTVJKrk3x00f2f8mv8PvxCkr/ne7a5Xkn+cZLXJPn0TG1N36skr0jy+Hi/aExftOifbbu+Vjln1yY5f0y/e+ac7Zptd8p2PjbOY43zev2if7bt+lrlnK3pd6F/Vy7+nJ2y/N8l+V/H9Jb6nrkCOF9XJVnq7se7+6+T3Jlk34L7RJLufrq7/2RM/0WSzyS59DSr7EtyZ3d/tbs/l2Qpy+eXxduX5PCYPpzkhpn6+3vZg0kurKpLFtA/ll2T5M+7+/OnaeN7tgDd/UdJTpxSXuv36rokR7r7RHc/l+RIkr1z7/xErXTOuvsPu/uFMftglv928qrGefv27n6wl/+V+v58/Tyzzlb5nq1mtd+F/l25gU53zsZVvJ9M8tun28Zm/Z4JgPN1aZInZ+afyulDBgtQVbuSvDrJR0fpreMWmkMnb3uKc7lZdJI/rKqPV9WBUbu4u58e019IcvGYds42lxvz4v9Q+p5tbmv9Xjl3m8v/mOUrDSddXlWfqKr/q6r+0ahdmuXzdJJzthhr+V3oe7Z5/KMkz3T3YzO1LfM9EwCZtKr61iS/k+TnuvvLSW5L8g+SXJnk6Sxf3mfz+OHufk2S65PcXFX/eHbh+L9rhjbeZKrqgiQ/luQ/j5Lv2Rbie7W1VNX/kuSFJL81Sk8n+c7ufnWSf5XkP1XVty+qf7yI34Vb15vz4v+puaW+ZwLgfB1LctnM/M5RYxOoqpdlOfz9Vnf/bpJ09zPd/bXu/pskv5Gv337mXG4C3X1svD+b5ENZPj/PnLy1c7w/O5o7Z5vH9Un+pLufSXzPtoi1fq+cu02gqv6HJP80yT8bwT3jNsIvjumPZ/kZsv8uy+dn9jZR52yDncPvQt+zTaCqzk/y3yf5wMnaVvueCYDz9VCS3VV1+fg/4DcmuWfBfSJ/e+/2HUk+092/MlOffUbsx5OcHPnpniQ3VtXLq+ryJLuz/FAvG6SqvqWqvu3kdJYHPPh0ls/NyREH9ye5e0zfk+QtY9TCq5M8P3NLGxvrRf+n1PdsS1jr9+r+JNdW1UXjNrZrR40NUlV7k/x8kh/r7q/M1HdU1Xlj+u9n+Xv1+DhvX66qq8d/E9+Sr59nNsA5/C7078rN4UeT/Fl3/+2tnVvte3b+ojuwnXX3C1X11iz/R/C8JIe6+5EFd4tlP5Tkp5J86uQQvkl+Mcmbq+rKLN/u9ESSf5Ek3f1IVd2V5NEs31pzc3d/bYP7PHUXJ/nQGD35/CT/qbv/oKoeSnJXVd2U5PNZfig7Se7L8oiFS0m+kuSnN77LjLD++ozv0vC/+55tHlX120l+JMmrquqpJLckuTVr+F5194mqemeW/4GaJO/o7rMd8II1WuWcvT3Lo0YeGb8nH+zuf5nlkQzfUVX/X5K/SfIvZ87NzyZ5X5JvzvIzg7PPDbKOVjlnP7LW34X+XblxVjpn3X1HvvGZ9mSLfc9q3CEAAADANucWUAAAgIkQAAEAACZCAAQAAJgIARAAAGAiBEAAAICJEAABAAAmQgAEAACYCAEQAABgIv5/DDL/CYKysk8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "fig, (ax, ay) = plt.subplots(2, 1)\n",
    "ax.bar(sentences_count.keys(), sentences_count.values())\n",
    "ay.bar(words_count.keys(), words_count.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d95cde15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sent_data = []\n",
    "# for k, v in sentences_count.items():\n",
    "#     sent_data.extend([k] * v)\n",
    "#\n",
    "# word_data = []\n",
    "# for k, v in words_count.items():\n",
    "#     word_data.extend([k] * v)\n",
    "\n",
    "# sent_data = [[k] * v for k, v in sentences_count.items()]\n",
    "# print(len(sent_data))\n",
    "# print(len(sent_data[0]))\n",
    "\n",
    "fig, (ax, ay) = plt.subplots(1, 2)\n",
    "ax.boxplot(sent_data)\n",
    "ay.boxplot(word_data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4ecb9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Making a new dataset out of the CnnDailymail for extractive training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d02cd2",
   "metadata": {
    "pycharm": {
     "name": "#%%  1%|▌                                                                             | 92/13368 [00:16<39:47,  5.56it/s]\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-22 12:05:18.743055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-22 12:05:18.772671: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-08-22 12:05:18.772685: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-08-22 12:05:18.773278: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-22 12:05:18.853605: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Getting dataset\n",
    "ds, ds_info = tfds.load('cnn_dailymail', with_info=True)\n",
    "# ds\n",
    "train = list(ds['train'])\n",
    "val = list(ds['validation'])\n",
    "test = list(ds['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af72a7",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "### In the following cell abstractive ground truths of CnnDailymail dataset are transformed into extractive ground truths for our model using Rouge-L maximization\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4d9a0",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                    | 10000/287113 [23:59<12:07:47,  6.35it/s]/tmp/ipykernel_9054/104891140.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  article_sentences=np.array(article_sentences_list),\n",
      "/tmp/ipykernel_9054/104891140.py:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  labels=np.array(labels_list),\n",
      " 61%|█████████████████████████████████████████▊                           | 173825/287113 [7:21:40<3:47:06,  8.31it/s]"
     ]
    }
   ],
   "source": [
    "save_dir = './preprocessed_cnn_dailymail'\n",
    "\n",
    "\n",
    "def get_article_and_highlights(obj) -> Tuple[str, str]:\n",
    "    return obj['article'].numpy().decode('utf-8'), obj['highlights'].numpy().decode('utf-8')\n",
    "\n",
    "\n",
    "def make_extractive_labels(e, rouge_diff_threshold: float = 0., score_to_use: str = 'rouge-l'):\n",
    "    article, ref = get_article_and_highlights(e)\n",
    "    article_sentences = sent_tokenize(article)\n",
    "    labels = [0] * len(article_sentences)\n",
    "    chosen_sentences = []\n",
    "    max_rouge_score = 0\n",
    "\n",
    "    for si, sentence in enumerate(article_sentences):\n",
    "        hyp = ' '.join(chosen_sentences + [sentence])\n",
    "        no_punct = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        if len(no_punct) > 0:\n",
    "            scores = rouge.get_scores(hyp, ref)[0]\n",
    "            if scores[score_to_use]['f'] > max_rouge_score + rouge_diff_threshold:\n",
    "                max_rouge_score = scores[score_to_use]['f']\n",
    "                chosen_sentences.append(sentence)\n",
    "                labels[si] = 1\n",
    "\n",
    "    return article_sentences, np.array(labels, dtype=np.uint8), ref\n",
    "\n",
    "\n",
    "def transform_data_to_extractive(dataset, save_dir, n_steps=10000):\n",
    "    labels_list = []\n",
    "    article_sentences_list = []\n",
    "    refs = []\n",
    "    step = 0\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        article_sentences, labels, ref = make_extractive_labels(dataset[i])\n",
    "        article_sentences_list.append(article_sentences)\n",
    "        labels_list.append(labels)\n",
    "        refs.append(ref)\n",
    "        if i > 0 and i % n_steps == 0:\n",
    "            np.savez_compressed(os.path.join(save_dir, str(step)),\n",
    "                                article_sentences=np.array(article_sentences_list),\n",
    "                                labels=np.array(labels_list),\n",
    "                                refs=np.array(refs))\n",
    "            article_sentences_list = []\n",
    "            labels_list = []\n",
    "            refs = []\n",
    "            step += 1\n",
    "    np.savez_compressed(os.path.join(save_dir, str(step)),\n",
    "                        article_sentences=np.array(article_sentences_list),\n",
    "                        labels=np.array(labels_list),\n",
    "                        refs=np.array(refs))\n",
    "\n",
    "    \n",
    "transform_data_to_extractive(train, os.path.join(save_dir, 'train'))\n",
    "# transform_data_to_extractive(val, os.path.join(save_dir, 'val'))\n",
    "# transform_data_to_extractive(test, os.path.join(save_dir, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26c5625",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# [<document_batch_dim>, <sentences_dim>, <words_dim>, <word_embedding_dim>]\n",
    "# [<document_batch_dim>, <labels_vec_dim>]\n",
    "\n",
    "class BiLstmBasedCustom(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim: int = 300,\n",
    "                 words_count: int = 150,\n",
    "                 sentences_count: int = 200,\n",
    "                 hidden_dim: int = 150):\n",
    "        super(BiLstmBasedCustom, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.words_count = words_count\n",
    "        self.sentences_count = sentences_count\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Sentence encoder\n",
    "\n",
    "        self.bilstm = nn.LSTM(self.embedding_dim,\n",
    "                              self.hidden_dim // 2,\n",
    "                              num_layers=1,\n",
    "                              bidirectional=True,\n",
    "                              batch_first=True)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(1, 8, 3)\n",
    "        self.bn0 = nn.BatchNorm2d(8)\n",
    "        self.mp0 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(8, 16, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.mp23 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.mp456 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(64, 128, 3)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(128, 128, 3)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        self.conv9 = nn.Conv2d(128, 128, 3)\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Other layers, aggregating sentence embeddings\n",
    "        self.doc_bilstm = nn.LSTM(128,\n",
    "                                  64,\n",
    "                                  bidirectional=True,\n",
    "                                  batch_first=True,\n",
    "                                  num_layers=1)\n",
    "        self.doc_linear0 = nn.Linear(128, 64)\n",
    "        self.doc_linear1 = nn.Linear(64, 32)\n",
    "        self.doc_linear2 = nn.Linear(32, 1)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _apply_sentence_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "            Applying sentence encoder layers to every sentence tensor passed\n",
    "            :param x: Tensor, containing list of word embedding for every word in a sentence\n",
    "            :return: Tensor, containing a single vector - embedding of the sentence\n",
    "        \"\"\"\n",
    "\n",
    "        cx, _ = self.bilstm(x)\n",
    "        cx = torch.reshape(cx, (cx.shape[0], 1, self.words_count, self.hidden_dim))\n",
    "\n",
    "        cx = self.conv0(cx)  # output shape: (8, 148, 148)\n",
    "        cx = self.bn0(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.mp0(cx)  # output_shape: (8, 74, 74)\n",
    "\n",
    "        cx = self.conv1(cx)  # output_shape: (16, 72, 72)\n",
    "        cx = self.bn1(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.mp1(cx)  # output_shape: (16, 36, 36)\n",
    "\n",
    "        cx = self.conv2(cx)  # output_shape:  (32, 34, 34)\n",
    "        cx = self.bn2(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.conv3(cx)  # output_shape: (32, 32, 32)\n",
    "        cx = self.bn3(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.mp23(cx)  # output_shape: (32, 16, 16)\n",
    "\n",
    "        cx = self.conv4(cx)   # output_shape: (64, 14, 14)\n",
    "        cx = self.bn4(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.conv5(cx)  # output_shape: (64, 12, 12)\n",
    "        cx = self.bn5(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.conv6(cx)  # output_shape: (64, 10, 10)\n",
    "        cx = self.bn6(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.mp456(cx)  # output_shape: (64, 5, 5)\n",
    "\n",
    "        cx = self.conv7(cx)  # output_shape: (128, 3, 3)\n",
    "        cx = self.bn7(cx)\n",
    "        cx = F.relu(cx)\n",
    "        cx = self.conv8(cx)  # output_shape: (128, 1, 1)\n",
    "        cx = self.bn8(cx)\n",
    "        cx = F.relu(cx)\n",
    "\n",
    "        cx = torch.flatten(cx, start_dim=1)\n",
    "\n",
    "        return cx\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Input shape: [<document_batch_dim>\n",
    "        #               <sentences_dim>,\n",
    "        #               <words_dim>,\n",
    "        #               <word_embedding_dim>]\n",
    "\n",
    "        hi_list = []\n",
    "        for si in range(self.sentences_count):\n",
    "            xi = x[:, si, :, :]  # slicing sentence\n",
    "            hi = self._apply_sentence_encoder(xi)  # getting stentence embedding\n",
    "            hi_list.append(hi)\n",
    "        hi_ = torch.stack(hi_list, dim=1)\n",
    "\n",
    "        hi_, _ = self.doc_bilstm(hi_)  # output_shape: (N, <sentences_count>, 128)\n",
    "\n",
    "        hi_ = self.doc_linear0(hi_)\n",
    "        hi_ = F.tanh(hi_)\n",
    "\n",
    "        hi_ = self.doc_linear1(hi_)\n",
    "        hi_ = F.tanh(hi_)\n",
    "\n",
    "        hi_ = self.doc_linear2(hi_)\n",
    "        hi_ = torch.flatten(hi_, start_dim=1)\n",
    "        output = F.sigmoid(hi_)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7396d5",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CnnDailymailDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Dataset class for files, generated during 'abstractive-to-extractive' labels transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dir,\n",
    "                 word_encoder: FastText,\n",
    "                 words_count: int = 150,\n",
    "                 sentences_count: int = 200):\n",
    "        self.word_encoder = word_encoder\n",
    "\n",
    "        self.words_count = words_count\n",
    "        self.sentences_count = sentences_count\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        assert os.path.exists(dir), f\"Directory {dir} was not found\"\n",
    "        self.article_sentences, self.labels, self.refs = [], [], []\n",
    "        for filename in os.listdir(dir):\n",
    "            data = np.load(os.path.join(dir, filename), allow_pickle=True)\n",
    "            self.article_sentences.extend(data['article_sentences'])\n",
    "            self.labels.extend(data['labels'])\n",
    "            self.refs.extend(data['refs'])\n",
    "        assert len(self.article_sentences) == len(self.labels) == len(self.refs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.article_sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        # Cropping sentences, as we cannot allow various input size for our model\n",
    "        chosen_sentences = self.article_sentences[item][:self.sentences_count]\n",
    "        chosen_labels = self.labels[item][:self.sentences_count]\n",
    "\n",
    "        # chosen_refs = self.refs[item]\n",
    "\n",
    "        # Encoding\n",
    "        encoded_sentences = []\n",
    "        for sentence in chosen_sentences:\n",
    "            encoded_sentence = []\n",
    "            words = word_tokenize(sentence, language=\"english\")[:self.words_count]\n",
    "            for word in words:\n",
    "                encoding = self.word_encoder.get_word_vector(word)\n",
    "                encoded_sentence.append(encoding)\n",
    "            encoded_sentence = np.array(encoded_sentence, dtype=np.float32)\n",
    "            \n",
    "            encoded_sentence = np.pad(encoded_sentence,\n",
    "                                      pad_width=((0, self.words_count - len(encoded_sentence)), (0, 0)))\n",
    "            encoded_sentences.append(encoded_sentence)\n",
    "\n",
    "\n",
    "        xs = np.array(encoded_sentences)\n",
    "        xs = np.pad(xs, pad_width=((0, self.sentences_count - len(encoded_sentences)), (0, 0), (0, 0)))\n",
    "\n",
    "        ys = np.array(chosen_labels)\n",
    "        mask = np.array([1] * len(chosen_labels))\n",
    "        \n",
    "        ys = np.pad(ys, pad_width=(0, self.sentences_count - len(encoded_sentences)))\n",
    "        mask = np.pad(mask, pad_width=(0, self.sentences_count - len(encoded_sentences)))\n",
    "        \n",
    "        return {'xs': torch.FloatTensor(xs).to(self.device),\n",
    "                'ys': torch.FloatTensor(ys).to(self.device),\n",
    "                'mask': torch.FloatTensor(mask).to(self.device)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a2ef0",
   "metadata": {},
   "source": [
    "Loading datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e33200",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '/home/anton/Work/interviews/aspose/repository/extractive_summarization/preprocessed_cnn_dailymail/train'\n",
    "val_dir = '/home/anton/Work/interviews/aspose/repository/extractive_summarization/preprocessed_cnn_dailymail/validation'\n",
    "\n",
    "train_dataset = CnnDailymailDataset(train_dir, ft_en)\n",
    "val_dataset = CnnDailymailDataset(val_dir, ft_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2131877",
   "metadata": {},
   "source": [
    "Creating dataloader, setting training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918d73f0",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "BiLstmBasedCustom(\n",
      "  (bilstm): LSTM(300, 75, batch_first=True, bidirectional=True)\n",
      "  (conv0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp456): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (doc_bilstm): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
      "  (doc_linear0): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (doc_linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (doc_linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "log_dir = './log_dir'\n",
    "weights_dir = './weights'\n",
    "writer = SummaryWriter(log_dir)\n",
    "train_steps = 400\n",
    "validation_steps = 200\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = BiLstmBasedCustom()\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642dade",
   "metadata": {},
   "source": [
    "### Training itself starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a460a606",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/400 [00:00<?, ?it/s]/home/anton/Work/interviews/aspose/repository/extractive_summarization/venv/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/anton/Work/interviews/aspose/repository/extractive_summarization/venv/lib/python3.8/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/anton/Work/interviews/aspose/repository/extractive_summarization/venv/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [13:19<00:00,  2.00s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [02:55<00:00,  1.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [13:53<00:00,  2.08s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [03:25<00:00,  1.03s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [14:19<00:00,  2.15s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [02:53<00:00,  1.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [13:54<00:00,  2.09s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [02:57<00:00,  1.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [12:51<00:00,  1.93s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [02:38<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        val_loss = 0\n",
    "        for bi, data in tqdm(enumerate(val_loader), total=validation_steps):\n",
    "            y_pred = model(data['xs'])\n",
    "            loss = F.binary_cross_entropy(y_pred, data['ys'], weight=data['mask'])\n",
    "            val_loss += ((1 / (bi + 1)) * (loss.item() - val_loss))\n",
    "            if bi >= validation_steps:\n",
    "                break\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Train\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for bi, data in tqdm(enumerate(train_loader), total=train_steps):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(data['xs'])\n",
    "        loss = F.binary_cross_entropy(y_pred, data['ys'], weight=data['mask'])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += ((1 / (bi + 1)) * (loss.item() - train_loss))\n",
    "        \n",
    "        if bi >= train_steps:\n",
    "            break\n",
    "        \n",
    "    # Validation\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(weights_dir, 'last.pt'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
